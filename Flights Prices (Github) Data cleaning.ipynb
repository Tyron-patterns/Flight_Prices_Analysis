{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "674f403f-e468-4936-99ea-88275f952499",
   "metadata": {},
   "source": [
    "# INTRODUCTION\n",
    "This project analyzes a dataset containing information about flights in India, with the aim of conducting a statistical evaluation of flight characteristics to understand ticket prices according to said characteristics.\n",
    "\n",
    "**Data source:**\n",
    "kaggle [link](https://www.kaggle.com/datasets/shubhambathwal/flight-price-prediction), \"Ease My Trip\", Udemy  \n",
    "\n",
    "## Tasks \n",
    "a) Does price vary with Airlines?  \n",
    "b) How is the price affected when tickets are bought in just 1 or 2 days before departure?  \n",
    "c) Does ticket price change based on the departure time and arrival time?  \n",
    "d) How does the price change with change in Source and Destination?  \n",
    "e) How does the ticket price vary between Economy and Business class?  \n",
    "\n",
    "## Scope of the project\n",
    "This study is part of a broader portfolio project designed to showcase my data analysis skills, including:\n",
    "- Statistical reasoning\n",
    "- Proficiency with core Python libraries (NumPy, Pandas, Matplotlib, Seaborn)\n",
    "- Automation principles\n",
    "- Overall analytical approach to working with structured data\n",
    "\n",
    "Although the dataset was originally intended for building a predictive model, the main focus of this project is on:\n",
    "- Data Cleaning\n",
    "- Feature Engineering\n",
    "- Exploratory Data Analysis (EDA)\n",
    "\n",
    "These processes are used to extract meaningful insights and prepare the data for potential modeling, rather than building a predictive algorithm itself.\n",
    "\n",
    "The entire study has been divided into three main sections (three deparate notebook files) to improve readability:\n",
    "\n",
    "### Data Cleaning\n",
    "This section demonstrates the process of cleaning a raw dataset by identifying inconsistencies, handling missing values, correcting formatting issues, and validating data integrity.  \n",
    "In short, preparing the dataset for further analysis.\n",
    "\n",
    "### Feature Engineering\n",
    "Here, the dataset is transformed to include new or restructured variables, making it more suitable for analysis or modeling tasks. While not all engineered features are necessary for the final EDA, they are included to demonstrate relevant techniques and problem-solving capabilities\n",
    "\n",
    "### Exploratory Data Analysis\n",
    "This is where key tasks are addressed through statistical evaluation and visualizations. Various trends, distributions, and relationships are explored to extract insights and support data-driven reasoning.\n",
    "\n",
    "Each task within these three main sections is documented with explanations of the relevant actions and insights.\n",
    "\n",
    "**NOTE**: as the project is intended for showcasing and practicing purposes, some steps (mainly in the FE section) are not strictly necessary for the completion of the tasks or the final analysis.  \n",
    "These intentional additions are meant to show familiraity with different data-preparation techniques.  \n",
    "Additonally, while data cleaning and the feature engineering are often to be intertwined and occur simultenously in a real workflow, separating them into distinct sections was a deliberate choice to improve structure and clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b500a6-4dfb-4519-a63a-4e8d622561b0",
   "metadata": {},
   "source": [
    "# DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28b556cd-59dd-47ee-bc9a-07fa15546684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "405e1413-7134-4c35-95d8-febfb0636fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('flight_price.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103a8427-c2f3-48e4-9dd7-bf8260fc0ff6",
   "metadata": {},
   "source": [
    "### 1. UNDERSTANDING THE DATA STRUCTURE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e8e049-9dc0-42ce-bb93-7017b8bcc030",
   "metadata": {},
   "source": [
    "#### 1.1 General info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7290f8-696b-4028-a0e6-95ca44ed02f4",
   "metadata": {},
   "source": [
    "preliminary exploration of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "d886a49c-c17c-4fd0-be40-48656a94ad38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date_of_Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep_Time</th>\n",
       "      <th>Arrival_Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Additional_Info</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>24/03/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR â†’ DEL</td>\n",
       "      <td>22:20</td>\n",
       "      <td>01:10 22 Mar</td>\n",
       "      <td>2h 50m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>3897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air India</td>\n",
       "      <td>1/05/2019</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU â†’ IXR â†’ BBI â†’ BLR</td>\n",
       "      <td>05:50</td>\n",
       "      <td>13:15</td>\n",
       "      <td>7h 25m</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>7662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>9/06/2019</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL â†’ LKO â†’ BOM â†’ COK</td>\n",
       "      <td>09:25</td>\n",
       "      <td>04:25 10 Jun</td>\n",
       "      <td>19h</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>13882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>12/05/2019</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU â†’ NAG â†’ BLR</td>\n",
       "      <td>18:05</td>\n",
       "      <td>23:30</td>\n",
       "      <td>5h 25m</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>6218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>01/03/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR â†’ NAG â†’ DEL</td>\n",
       "      <td>16:50</td>\n",
       "      <td>21:35</td>\n",
       "      <td>4h 45m</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>13302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10678</th>\n",
       "      <td>Air Asia</td>\n",
       "      <td>9/04/2019</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU â†’ BLR</td>\n",
       "      <td>19:55</td>\n",
       "      <td>22:25</td>\n",
       "      <td>2h 30m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>4107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10679</th>\n",
       "      <td>Air India</td>\n",
       "      <td>27/04/2019</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU â†’ BLR</td>\n",
       "      <td>20:45</td>\n",
       "      <td>23:20</td>\n",
       "      <td>2h 35m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>4145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10680</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>27/04/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>BLR â†’ DEL</td>\n",
       "      <td>08:20</td>\n",
       "      <td>11:20</td>\n",
       "      <td>3h</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>7229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10681</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>01/03/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR â†’ DEL</td>\n",
       "      <td>11:30</td>\n",
       "      <td>14:10</td>\n",
       "      <td>2h 40m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>12648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10682</th>\n",
       "      <td>Air India</td>\n",
       "      <td>9/05/2019</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL â†’ GOI â†’ BOM â†’ COK</td>\n",
       "      <td>10:55</td>\n",
       "      <td>19:15</td>\n",
       "      <td>8h 20m</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>11753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10683 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Airline Date_of_Journey    Source Destination  \\\n",
       "0           IndiGo      24/03/2019  Banglore   New Delhi   \n",
       "1        Air India       1/05/2019   Kolkata    Banglore   \n",
       "2      Jet Airways       9/06/2019     Delhi      Cochin   \n",
       "3           IndiGo      12/05/2019   Kolkata    Banglore   \n",
       "4           IndiGo      01/03/2019  Banglore   New Delhi   \n",
       "...            ...             ...       ...         ...   \n",
       "10678     Air Asia       9/04/2019   Kolkata    Banglore   \n",
       "10679    Air India      27/04/2019   Kolkata    Banglore   \n",
       "10680  Jet Airways      27/04/2019  Banglore       Delhi   \n",
       "10681      Vistara      01/03/2019  Banglore   New Delhi   \n",
       "10682    Air India       9/05/2019     Delhi      Cochin   \n",
       "\n",
       "                       Route Dep_Time  Arrival_Time Duration Total_Stops  \\\n",
       "0                  BLR â†’ DEL    22:20  01:10 22 Mar   2h 50m    non-stop   \n",
       "1      CCU â†’ IXR â†’ BBI â†’ BLR    05:50         13:15   7h 25m     2 stops   \n",
       "2      DEL â†’ LKO â†’ BOM â†’ COK    09:25  04:25 10 Jun      19h     2 stops   \n",
       "3            CCU â†’ NAG â†’ BLR    18:05         23:30   5h 25m      1 stop   \n",
       "4            BLR â†’ NAG â†’ DEL    16:50         21:35   4h 45m      1 stop   \n",
       "...                      ...      ...           ...      ...         ...   \n",
       "10678              CCU â†’ BLR    19:55         22:25   2h 30m    non-stop   \n",
       "10679              CCU â†’ BLR    20:45         23:20   2h 35m    non-stop   \n",
       "10680              BLR â†’ DEL    08:20         11:20       3h    non-stop   \n",
       "10681              BLR â†’ DEL    11:30         14:10   2h 40m    non-stop   \n",
       "10682  DEL â†’ GOI â†’ BOM â†’ COK    10:55         19:15   8h 20m     2 stops   \n",
       "\n",
       "      Additional_Info  Price  \n",
       "0             No info   3897  \n",
       "1             No info   7662  \n",
       "2             No info  13882  \n",
       "3             No info   6218  \n",
       "4             No info  13302  \n",
       "...               ...    ...  \n",
       "10678         No info   4107  \n",
       "10679         No info   4145  \n",
       "10680         No info   7229  \n",
       "10681         No info  12648  \n",
       "10682         No info  11753  \n",
       "\n",
       "[10683 rows x 11 columns]"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the dataset!\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "56f1d3f8-0f69-49d7-8750-ba223e2758bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10683, 11)"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieving the total number of rows (records) and columns (features)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "b3660aa5-2c48-4129-8d54-2cd0b187ecf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10683 entries, 0 to 10682\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Airline          10683 non-null  object\n",
      " 1   Date_of_Journey  10683 non-null  object\n",
      " 2   Source           10683 non-null  object\n",
      " 3   Destination      10683 non-null  object\n",
      " 4   Route            10682 non-null  object\n",
      " 5   Dep_Time         10683 non-null  object\n",
      " 6   Arrival_Time     10683 non-null  object\n",
      " 7   Duration         10683 non-null  object\n",
      " 8   Total_Stops      10682 non-null  object\n",
      " 9   Additional_Info  10683 non-null  object\n",
      " 10  Price            10683 non-null  int64 \n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 918.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Retrieving general information about missing values and data dtype\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245d150f-b8ba-46e3-b544-7268b601e332",
   "metadata": {},
   "source": [
    "#### Insights - general info:\n",
    "The dataset contains 11 features and 10683 records.  \n",
    "At this moment, the features (10) are mostly in the form of strings, including those containing dates and times or values that can be converted to numbers (Total_Stops): one of the main objective of the data cleaning process will be to convert such features into the correct data type.  \n",
    "The only column whose values are stored as integers is 'Price', which is also the target variable.\n",
    "The dataset is quite consistent in terms of missing values, with only two missing values: 1 in 'Route' and 1 in 'Total_Stops'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64f370a-d6eb-4b49-b5ca-e36a3f3fbffb",
   "metadata": {},
   "source": [
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·\n",
    "#### 1.2 Finding unique values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d09c57c-c7cc-4169-b49a-a6ed5054e0a1",
   "metadata": {},
   "source": [
    "Checking unique values and their count for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "66b82425-0092-4e1d-a348-3f682e6c4fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Airline'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "84fe0a03-fc3b-439e-8738-aafb8caab996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['IndiGo', 'Air India', 'Jet Airways', 'SpiceJet',\n",
       "       'Multiple carriers', 'GoAir', 'Vistara', 'Air Asia',\n",
       "       'Vistara Premium economy', 'Jet Airways Business',\n",
       "       'Multiple carriers Premium economy', 'Trujet'], dtype=object)"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Airline'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "4a22e782-3d31-48f8-afcd-f42e8f76d88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Source'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "eac29409-970d-4f8d-8066-ba06bf40c8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Banglore', 'Kolkata', 'Delhi', 'Chennai', 'Mumbai'], dtype=object)"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Source'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "e84ab0a7-7c67-483f-bf22-00eb7519d634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Destination'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "f2e61395-3a22-41b8-8d30-3c80805d097b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['New Delhi', 'Banglore', 'Cochin', 'Kolkata', 'Delhi', 'Hyderabad'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Destination'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "10f02942-0b39-4ad4-bdb7-d7a8c34c4d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Route'].nunique() # There are too many different Route: in this case looking at the unique values is useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "68cb863a-d2c1-45c0-b00b-1389b8b0cff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Total_Stops'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "b4c0fa19-29c6-4b35-b094-fb06d3eb9cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['non-stop', '2 stops', '1 stop', '3 stops', nan, '4 stops'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Total_Stops'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "5a5b0ee4-f8c3-4da2-b954-6f1ecac7a5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Additional_Info'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "fed1667e-cee3-4e40-a21f-25a86776d66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No info', 'In-flight meal not included',\n",
       "       'No check-in baggage included', '1 Short layover', 'No Info',\n",
       "       '1 Long layover', 'Change airports', 'Business class',\n",
       "       'Red-eye flight', '2 Long layover'], dtype=object)"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Additional_Info'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "fa8db1d4-05a2-4c7c-bb35-a50522c4649d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking unique values for numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "cfdd7f9c-024e-4d98-8b14-8ae87fd98785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date_of_Journey'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "71441305-a638-4dec-9aff-253d4e0a9b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Dep_Time'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "32a1a58b-8887-4d95-b760-0490527ff24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1343"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Arrival_Time'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "e9378af0-ff9a-45d7-a363-5a096c89021a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Duration'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "1a214be9-5228-4b38-8a61-feae7825557e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1870"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Price'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9991c4d9-fefd-427b-9891-5ff6f6db3b17",
   "metadata": {},
   "source": [
    "#### Insights - unique values\n",
    "In this dataset, many values in the numerical features â€” such as Price â€” are rarely repeated. As a result, applying .unique() on these columns would return a very long list of distinct values, which is not easily interpretable. In these cases, it is often more useful to use .nunique() to simply count the number of unique entries, which helps assess whether a .unique() check is worth running at all.\n",
    "\n",
    "On the other hand, categorical features typically contain a limited set of unique values. For instance, the Total_Stops column likely includes only a few distinct entries, making it helpful to examine both the unique values and their count.\n",
    "However, this assumption has limitations. Some categorical features â€” like Route â€” can still have a high number of unique values (e.g., 129 distinct routes), in which case listing them all is not particularly insightful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f6abe6-8e13-4577-b418-e9f66182808d",
   "metadata": {},
   "source": [
    "### INSIGHTS - DATA STRUCTURE\n",
    "\n",
    "Features:\n",
    "\n",
    "1) **Airline**: categorical feature with the name of the airlines containing 12 unique values in the form of strings\n",
    "   \n",
    "2) **Date_of_Journey**: date feature with the date of departure in the form of string - to be converted to date\n",
    "\n",
    "   \n",
    "3) **Source**: categorical feature with the name of the source city containing 6 unique values in the form of string\n",
    "\n",
    " \n",
    "4) **Destination**: categorical feature with the name of the destination city containing 6 unique values in the form of string\n",
    "\n",
    "\n",
    "5) **Route**: categorical feature with the acronyms of the airports (source, stops and destination) in the form of string - 1 missing value\n",
    "\n",
    "\n",
    "6) **Dep_Time**: date categorical feature with the time of departure in the form of string and format 'HH:MM' - to be converted to time\n",
    "\n",
    "\n",
    "7) **Arrival_Time**: date feature with the time and (in some cases) date of arrival in the form of string and format 'HH:MM dd mm' - to be converted to time/datetime\n",
    "\n",
    " \n",
    "8) **Duration**: shows the total duration of each flight (including stops)in the form of strings and format 'xx'h 'yy'm - to be converted to 'HH:MM'\n",
    "\n",
    " \n",
    "9) **Total_Stops**: discrete numerical feature derived from 'Route' with the number of stops containing 5 unique values in the form of string - 1 missing value; to be converted to integer\n",
    "\n",
    " \n",
    "10) **Additiona_Info**: categorical value with information about the flight (meal, layovers, baggages, etc) containing 10 unique values in the form of string\n",
    "\n",
    "    \n",
    "11) **Price**: numerical feature with the price of every flight. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4276279-d50e-42cc-96cf-eaca531df247",
   "metadata": {},
   "source": [
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·\n",
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·\n",
    "After inspecting the dataset, a copy of it will be cretated for manipulation purposes, so to leave the original one as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "9a9028b6-9390-46f5-8cb0-805e6ddcc9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4e82db-15a0-488f-a43f-e89341683a00",
   "metadata": {},
   "source": [
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·\n",
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049f97aa-ed55-4fd7-b9b5-3e625deaec03",
   "metadata": {},
   "source": [
    "### 2.  IDENTIFYING AND HANDLING DUPLICATE ROWS\n",
    "Identifying and dropping duplicate rows helps eliminate noise when performing statistical analysis, as duplicates can distort metrics such as mean, mode, and standard deviation, and can skew the shape of distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4c6bbb-3835-4106-b9c7-b9dff7f1283a",
   "metadata": {},
   "source": [
    "#### 2.1 Finding duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "534e812c-ed41-4440-9c97-62cf2be328be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10683, 11)"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of rows (records) and Columns (features)\n",
    "df_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "c3e0c316-bd2e-4f95-85e2-ba5c425c11de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of duplicated rows, excluding the first row\n",
    "duplicated = df_copy.duplicated()  #default parameter for duplicated: keep = 'first'\n",
    "duplicated.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "67eda037-542b-4e92-b3d6-560d1eb15e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "415"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of duplicated rows, inclduing the first record\n",
    "dups = df_copy.duplicated(keep = False) \n",
    "dups.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "ec0c185a-348f-4bd5-b8fa-1d8876a359f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2634      Vistara\n",
       "5470      Vistara\n",
       "1535     SpiceJet\n",
       "2870     SpiceJet\n",
       "7395     SpiceJet\n",
       "          ...    \n",
       "8640    Air India\n",
       "1786    Air India\n",
       "8613    Air India\n",
       "8602    Air India\n",
       "5483    Air India\n",
       "Name: Airline, Length: 415, dtype: object"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST: on one feature (Airline)\n",
    "df_copy[df_copy.duplicated(keep=False)]['Airline'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "bb3b0bd5-00c0-4b7f-abb4-f9fb241fcc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date_of_Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep_Time</th>\n",
       "      <th>Arrival_Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Additional_Info</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2634</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>24/03/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR â†’ DEL</td>\n",
       "      <td>11:30</td>\n",
       "      <td>14:10</td>\n",
       "      <td>2h 40m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>5403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5470</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>24/03/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR â†’ DEL</td>\n",
       "      <td>11:30</td>\n",
       "      <td>14:10</td>\n",
       "      <td>2h 40m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>5403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>SpiceJet</td>\n",
       "      <td>24/03/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR â†’ DEL</td>\n",
       "      <td>20:30</td>\n",
       "      <td>23:20</td>\n",
       "      <td>2h 50m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No check-in baggage included</td>\n",
       "      <td>3873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2870</th>\n",
       "      <td>SpiceJet</td>\n",
       "      <td>24/03/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR â†’ DEL</td>\n",
       "      <td>05:45</td>\n",
       "      <td>08:35</td>\n",
       "      <td>2h 50m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No check-in baggage included</td>\n",
       "      <td>4273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7395</th>\n",
       "      <td>SpiceJet</td>\n",
       "      <td>03/03/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR â†’ DEL</td>\n",
       "      <td>20:30</td>\n",
       "      <td>23:20</td>\n",
       "      <td>2h 50m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>6860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8640</th>\n",
       "      <td>Air India</td>\n",
       "      <td>3/06/2019</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL â†’ AMD â†’ BOM â†’ COK</td>\n",
       "      <td>19:45</td>\n",
       "      <td>19:15 04 Jun</td>\n",
       "      <td>23h 30m</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>10441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>Air India</td>\n",
       "      <td>15/06/2019</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL â†’ AMD â†’ BOM â†’ COK</td>\n",
       "      <td>19:45</td>\n",
       "      <td>19:15 16 Jun</td>\n",
       "      <td>23h 30m</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>9653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8613</th>\n",
       "      <td>Air India</td>\n",
       "      <td>27/06/2019</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL â†’ AMD â†’ BOM â†’ COK</td>\n",
       "      <td>16:40</td>\n",
       "      <td>19:15 28 Jun</td>\n",
       "      <td>26h 35m</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>9653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8602</th>\n",
       "      <td>Air India</td>\n",
       "      <td>27/06/2019</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL â†’ AMD â†’ BOM â†’ COK</td>\n",
       "      <td>19:45</td>\n",
       "      <td>19:15 28 Jun</td>\n",
       "      <td>23h 30m</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>9653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5483</th>\n",
       "      <td>Air India</td>\n",
       "      <td>27/05/2019</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL â†’ GOI â†’ BOM â†’ COK</td>\n",
       "      <td>22:00</td>\n",
       "      <td>19:15 28 May</td>\n",
       "      <td>21h 15m</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>10231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>415 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Airline Date_of_Journey    Source Destination                  Route  \\\n",
       "2634    Vistara      24/03/2019  Banglore   New Delhi              BLR â†’ DEL   \n",
       "5470    Vistara      24/03/2019  Banglore   New Delhi              BLR â†’ DEL   \n",
       "1535   SpiceJet      24/03/2019  Banglore   New Delhi              BLR â†’ DEL   \n",
       "2870   SpiceJet      24/03/2019  Banglore   New Delhi              BLR â†’ DEL   \n",
       "7395   SpiceJet      03/03/2019  Banglore   New Delhi              BLR â†’ DEL   \n",
       "...         ...             ...       ...         ...                    ...   \n",
       "8640  Air India       3/06/2019     Delhi      Cochin  DEL â†’ AMD â†’ BOM â†’ COK   \n",
       "1786  Air India      15/06/2019     Delhi      Cochin  DEL â†’ AMD â†’ BOM â†’ COK   \n",
       "8613  Air India      27/06/2019     Delhi      Cochin  DEL â†’ AMD â†’ BOM â†’ COK   \n",
       "8602  Air India      27/06/2019     Delhi      Cochin  DEL â†’ AMD â†’ BOM â†’ COK   \n",
       "5483  Air India      27/05/2019     Delhi      Cochin  DEL â†’ GOI â†’ BOM â†’ COK   \n",
       "\n",
       "     Dep_Time  Arrival_Time Duration Total_Stops  \\\n",
       "2634    11:30         14:10   2h 40m    non-stop   \n",
       "5470    11:30         14:10   2h 40m    non-stop   \n",
       "1535    20:30         23:20   2h 50m    non-stop   \n",
       "2870    05:45         08:35   2h 50m    non-stop   \n",
       "7395    20:30         23:20   2h 50m    non-stop   \n",
       "...       ...           ...      ...         ...   \n",
       "8640    19:45  19:15 04 Jun  23h 30m     2 stops   \n",
       "1786    19:45  19:15 16 Jun  23h 30m     2 stops   \n",
       "8613    16:40  19:15 28 Jun  26h 35m     2 stops   \n",
       "8602    19:45  19:15 28 Jun  23h 30m     2 stops   \n",
       "5483    22:00  19:15 28 May  21h 15m     2 stops   \n",
       "\n",
       "                   Additional_Info  Price  \n",
       "2634                       No info   5403  \n",
       "5470                       No info   5403  \n",
       "1535  No check-in baggage included   3873  \n",
       "2870  No check-in baggage included   4273  \n",
       "7395                       No info   6860  \n",
       "...                            ...    ...  \n",
       "8640                       No info  10441  \n",
       "1786                       No info   9653  \n",
       "8613                       No info   9653  \n",
       "8602                       No info   9653  \n",
       "5483                       No info  10231  \n",
       "\n",
       "[415 rows x 11 columns]"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test: Ordering duplicated features by Airline\n",
    "df_copy[df_copy.duplicated(keep=False)].sort_values(by= 'Airline', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "8185758c-68ee-48cc-8491-80da82deaec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.059346625479734"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of repeated records (excluding the first one)\n",
    "(220/10683)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a5f83b-5e35-434b-af40-f4195e5bce5b",
   "metadata": {},
   "source": [
    "#### Insights - duplicate rows\n",
    "Number of duplicated rows:\n",
    "- 220 excluding the first/original record\n",
    "- 415 including the first record\n",
    "\n",
    "This indicates that some records have more than one duplicate.  \n",
    "\n",
    "In this specific dataset, duplicates don't add any important information to the analysis as they are not a simptom of repeated behaviours: if a flight has the same identical info as another one (airline, date of departure and arrival, source, destination, etc.), they are necessarely the same flight as there can not be two identical flights at the same time.  \n",
    "\n",
    "Additionally, the percentage of duplicated records excluding the first is 2.0% of the total, which seems a negligible amount.  \n",
    "\n",
    "For these reasons, removal of duplicate shouldn't affect the study."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f123579-58d8-43e5-bae4-e74c0ebfb684",
   "metadata": {},
   "source": [
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·\n",
    "#### 2.2 Removing duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "860d524d-7d58-4b60-98f4-ba0b5e1dec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all the duplicates rows\n",
    "df_copy = df_copy.drop_duplicates(keep = 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "8e563787-7366-4690-a9bf-8bda02f24a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10463, 11)"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following 2 are a check to make sure the process worked as intended\n",
    "df_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "619f1ce1-5a02-4887-ae38-ed96a96ced1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Further check on elimination of duplicate rows\n",
    "df_copy.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cea93c-7ae8-43a0-b9f4-318f010ec724",
   "metadata": {},
   "source": [
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·\n",
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·\n",
    "### 3. IDENTIFYING AND HANDLING MISSING VALUES (preliminary check)\n",
    "Missing values have a specular effect compared to duplicates and the results of keeping them when not necessary or not handling them properly through statistical methods can also negatively affect statistical evaluations\n",
    "\n",
    "df.info() has already indicated the presence of only two missing values in total: one in Route and one in Total_Stops.  \n",
    "The next step will be about retrieving the related rows and evaluating how to handle them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "33dde870-2492-433c-a158-a4ec6317b685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date_of_Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep_Time</th>\n",
       "      <th>Arrival_Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Additional_Info</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9039</th>\n",
       "      <td>Air India</td>\n",
       "      <td>6/05/2019</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09:45</td>\n",
       "      <td>09:25 07 May</td>\n",
       "      <td>23h 40m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No info</td>\n",
       "      <td>7480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Airline Date_of_Journey Source Destination Route Dep_Time  \\\n",
       "9039  Air India       6/05/2019  Delhi      Cochin   NaN    09:45   \n",
       "\n",
       "      Arrival_Time Duration Total_Stops Additional_Info  Price  \n",
       "9039  09:25 07 May  23h 40m         NaN         No info   7480  "
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing values in Route\n",
    "df_copy[df_copy['Route'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "a3babccb-6947-4a4b-92f1-3d4b5f71a7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date_of_Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep_Time</th>\n",
       "      <th>Arrival_Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Additional_Info</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9039</th>\n",
       "      <td>Air India</td>\n",
       "      <td>6/05/2019</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09:45</td>\n",
       "      <td>09:25 07 May</td>\n",
       "      <td>23h 40m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No info</td>\n",
       "      <td>7480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Airline Date_of_Journey Source Destination Route Dep_Time  \\\n",
       "9039  Air India       6/05/2019  Delhi      Cochin   NaN    09:45   \n",
       "\n",
       "      Arrival_Time Duration Total_Stops Additional_Info  Price  \n",
       "9039  09:25 07 May  23h 40m         NaN         No info   7480  "
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing values in Total_Stops\n",
    "df_copy[df_copy['Total_Stops'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c349e0-0973-4cd9-842c-84d7b5a0e1c4",
   "metadata": {},
   "source": [
    "Both missing records for the two features appear to be on the same row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "e1ded07e-fd8e-4b22-ad8b-20d1af0cdead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date_of_Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep_Time</th>\n",
       "      <th>Arrival_Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Additional_Info</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9039</th>\n",
       "      <td>Air India</td>\n",
       "      <td>6/05/2019</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09:45</td>\n",
       "      <td>09:25 07 May</td>\n",
       "      <td>23h 40m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No info</td>\n",
       "      <td>7480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Airline Date_of_Journey Source Destination Route Dep_Time  \\\n",
       "9039  Air India       6/05/2019  Delhi      Cochin   NaN    09:45   \n",
       "\n",
       "      Arrival_Time Duration Total_Stops Additional_Info  Price  \n",
       "9039  09:25 07 May  23h 40m         NaN         No info   7480  "
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking both columns with logical operator '|' (= 'or') to confirm NaN is on the same row \n",
    "df_copy[df_copy['Route'].isnull() | df_copy['Total_Stops'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6627f90e-1c2d-4333-9d4b-e481926e2020",
   "metadata": {},
   "source": [
    "#### INSIGHTS - missing values\n",
    "As stated, there are only two missing values in the dataset, one in route and one in destination.  \n",
    "Additionally, the check performed on both features indicates that such values belong to the same row â€” which corresponds to a single record.  \n",
    "All this suggests that dropping said row is a safe choice.\n",
    "\n",
    "In fact:  \n",
    "- Only one record is affected, so no significant data will be lost.\n",
    "\n",
    "- Imputation would be unreliable here, since there's not enough context to guess them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "309afee7-a79b-4ee0-bdce-31f3066d619c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the row with missing values: 9039 is the row with the missing value (nan)\n",
    "\n",
    "df_copy.drop(9039, inplace = True) # df_copy = df_copy.drop(9039)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "2b013830-4bbf-4400-9a46-4c573fddaf1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date_of_Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep_Time</th>\n",
       "      <th>Arrival_Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Additional_Info</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Airline, Date_of_Journey, Source, Destination, Route, Dep_Time, Arrival_Time, Duration, Total_Stops, Additional_Info, Price]\n",
       "Index: []"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if the row was correctly dropped\n",
    "df_copy[df_copy['Route'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a7c73c-5734-4abb-ab67-3b40183b423c",
   "metadata": {},
   "source": [
    "### 4. FIXING FORMAT AND STRUCTURAL ISSUES\n",
    "This process aims to standardize data formats to ensure consistency in the dataset and enable proper comparisons and operations across different columns with similar features using vectorized methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6171efc4-532c-4299-be29-e2ffa8159eb4",
   "metadata": {},
   "source": [
    "#### 4.1 Extracting time from Arrival_Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "9e7bf2cf-761b-43cd-999d-d10403241192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        01:10\n",
       "1        13:15\n",
       "2        04:25\n",
       "3        23:30\n",
       "4        21:35\n",
       "         ...  \n",
       "10678    22:25\n",
       "10679    23:20\n",
       "10680    11:20\n",
       "10681    14:10\n",
       "10682    19:15\n",
       "Name: Arrival_Time_Hour, Length: 10462, dtype: object"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slippting minutes on the space and retrieving time from Arrival_Time\n",
    "df_copy['Arrival_Time_Hour'] = df_copy['Arrival_Time'].str.split(' ').str[0]\n",
    "df_copy['Arrival_Time_Hour']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac37ab12-81e1-4fd0-bbdf-098b57c6f236",
   "metadata": {},
   "source": [
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·\n",
    "#### 4.2 Extracting time from Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "445127cd-760c-4c67-9154-bb7c468f0932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2:50\n",
       "1         7:25\n",
       "2        19:00\n",
       "3         5:25\n",
       "4         4:45\n",
       "         ...  \n",
       "10678     2:30\n",
       "10679     2:35\n",
       "10680     3:00\n",
       "10681     2:40\n",
       "10682     8:20\n",
       "Name: Duration, Length: 10462, dtype: object"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing symbols in Duration \n",
    "df_copy['Duration']=df['Duration'].str.replace('h ',':')\n",
    "df_copy['Duration'] = df_copy['Duration'].str.replace('h', ':00')\n",
    "df_copy['Duration'] = df_copy['Duration'].str.replace('m','')\n",
    "df_copy['Duration']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff1f29f-039f-40d6-bbdc-5f960cafd62d",
   "metadata": {},
   "source": [
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·\n",
    "#### 4.3 Extracting the number of stops from Total_Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "a7dd0c7a-0897-4a6c-b570-b382406a44df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing words and splitting/retrieving strings in Total_Stops\n",
    "df_copy['Total_Stops'] = df_copy['Total_Stops'].str.replace('non-stop','0')\n",
    "df_copy['Total_Stops'] = df_copy['Total_Stops'].str.split(' ').str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d906a24f-fade-48fb-878c-c50db37c2f0e",
   "metadata": {},
   "source": [
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·\n",
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·\n",
    "### 5. CONVERTING DATA TYPES\n",
    "The conversion completes the normalization process by converting data in the appropriate types, allowing to perform comparions and other operations across different columns with similar features using vectorized methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eda218b-de9e-486e-a05a-b36de6ef07db",
   "metadata": {},
   "source": [
    "#### 5.1 Converting Date_of_Journey from string to timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "ce5fab82-4fff-4781-9457-00392016ed12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gs/d24257s15q1bzbn_vyvcxhb00000gp/T/ipykernel_96221/651070924.py:1: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_copy['Date_of_Journey'] = pd.to_datetime(df_copy['Date_of_Journey'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       2019-03-24\n",
       "1       2019-05-01\n",
       "2       2019-06-09\n",
       "3       2019-05-12\n",
       "4       2019-03-01\n",
       "           ...    \n",
       "10678   2019-04-09\n",
       "10679   2019-04-27\n",
       "10680   2019-04-27\n",
       "10681   2019-03-01\n",
       "10682   2019-05-09\n",
       "Name: Date_of_Journey, Length: 10462, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 644,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Date_of_Journey'] = pd.to_datetime(df_copy['Date_of_Journey'])\n",
    "df_copy['Date_of_Journey']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7142d220-8493-4ef4-8199-a90250bdd32b",
   "metadata": {},
   "source": [
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·\n",
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·\n",
    "#### 5.2 Converting Dep_Time from string to datestamp (HH:MM)\n",
    "Here and in the next step, 2 columns will be created:\n",
    "- one with just the time (H:M) for clarity when reading the dataset\n",
    "- one with a dummy date, which is necessary to perform vectorized operations between times in pandas\n",
    "\n",
    "Once the Feature Ingenireeing process is performed, it will be easy to decide which one to keep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf02b7f-f557-4f21-a9eb-c2ee6d83f0b9",
   "metadata": {},
   "source": [
    "##### 5.2.1. Creating a column whit a dummy date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "7457dc84-1bd3-445e-8a7f-9e542629ca21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dep_Time_Dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1900-01-01 22:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1900-01-01 05:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1900-01-01 09:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1900-01-01 18:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1900-01-01 16:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10678</th>\n",
       "      <td>1900-01-01 19:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10679</th>\n",
       "      <td>1900-01-01 20:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10680</th>\n",
       "      <td>1900-01-01 08:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10681</th>\n",
       "      <td>1900-01-01 11:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10682</th>\n",
       "      <td>1900-01-01 10:55:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10462 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Dep_Time_Dummy\n",
       "0     1900-01-01 22:20:00\n",
       "1     1900-01-01 05:50:00\n",
       "2     1900-01-01 09:25:00\n",
       "3     1900-01-01 18:05:00\n",
       "4     1900-01-01 16:50:00\n",
       "...                   ...\n",
       "10678 1900-01-01 19:55:00\n",
       "10679 1900-01-01 20:45:00\n",
       "10680 1900-01-01 08:20:00\n",
       "10681 1900-01-01 11:30:00\n",
       "10682 1900-01-01 10:55:00\n",
       "\n",
       "[10462 rows x 1 columns]"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a new column with a dummy Date\n",
    "df_copy['Dep_Time_Dummy']=pd.to_datetime(df_copy['Dep_Time'], format = '%H:%M')\n",
    "df_copy[['Dep_Time_Dummy']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2f9561-da8a-428f-b5e5-5179e9e470bd",
   "metadata": {},
   "source": [
    "##### 5.2.2. Creating a column whit just the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "d909331e-79af-4905-9ef0-81756ac8ffea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gs/d24257s15q1bzbn_vyvcxhb00000gp/T/ipykernel_96221/1711639493.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_copy['Dep_Time_Hour']=pd.to_datetime(df_copy['Dep_Time']).dt.time  # the parameter format = '%H:%M' is optional\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dep_Time_Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10678</th>\n",
       "      <td>19:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10679</th>\n",
       "      <td>20:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10680</th>\n",
       "      <td>08:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10681</th>\n",
       "      <td>11:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10682</th>\n",
       "      <td>10:55:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10462 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Dep_Time_Hour\n",
       "0          22:20:00\n",
       "1          05:50:00\n",
       "2          09:25:00\n",
       "3          18:05:00\n",
       "4          16:50:00\n",
       "...             ...\n",
       "10678      19:55:00\n",
       "10679      20:45:00\n",
       "10680      08:20:00\n",
       "10681      11:30:00\n",
       "10682      10:55:00\n",
       "\n",
       "[10462 rows x 1 columns]"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a column with just the time\n",
    "df_copy['Dep_Time_Hour']=pd.to_datetime(df_copy['Dep_Time']).dt.time  # the parameter format = '%H:%M' is optional\n",
    "df_copy[['Dep_Time_Hour']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce9eb82-ebc6-4650-bdd5-22b31224b218",
   "metadata": {},
   "source": [
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·\n",
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·\n",
    "#### 5.3 Converting Arrival_Time from string to timestamp (HH:MM)\n",
    "Since records in Arrival_Time present, along with the time, the date of arrival - for flights that have a shift in the day of arrival - the first step will be to separate these two variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55795374-e8cf-49af-be20-65c50262c973",
   "metadata": {},
   "source": [
    "##### 5.3.1. Creating a column with dummy date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "d9cf976f-7221-4996-8f39-b7c858df73b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1900-01-01 01:10:00\n",
       "1       1900-01-01 13:15:00\n",
       "2       1900-01-01 04:25:00\n",
       "3       1900-01-01 23:30:00\n",
       "4       1900-01-01 21:35:00\n",
       "                ...        \n",
       "10678   1900-01-01 22:25:00\n",
       "10679   1900-01-01 23:20:00\n",
       "10680   1900-01-01 11:20:00\n",
       "10681   1900-01-01 14:10:00\n",
       "10682   1900-01-01 19:15:00\n",
       "Name: Arrival_Time_Dummy, Length: 10462, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#column with the dummy date\n",
    "df_copy['Arrival_Time_Dummy'] = pd.to_datetime(df_copy['Arrival_Time_Hour'], format = '%H:%M')\n",
    "df_copy['Arrival_Time_Dummy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06662084-1962-46fa-8c8e-a5181679e1da",
   "metadata": {},
   "source": [
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f85427a-6b3a-4983-9459-0b9173705e85",
   "metadata": {},
   "source": [
    "##### 5.3.2 Crating a column whit just the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "a1b664a6-711f-4865-a8f7-8913136ffba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        01:10:00\n",
       "1        13:15:00\n",
       "2        04:25:00\n",
       "3        23:30:00\n",
       "4        21:35:00\n",
       "           ...   \n",
       "10678    22:25:00\n",
       "10679    23:20:00\n",
       "10680    11:20:00\n",
       "10681    14:10:00\n",
       "10682    19:15:00\n",
       "Name: Arrival_Time_Hour, Length: 10462, dtype: object"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Column with just the time with .dt.time\n",
    "df_copy['Arrival_Time_Hour'] = pd.to_datetime(df_copy['Arrival_Time_Hour'], format = '%H:%M').dt.time\n",
    "df_copy['Arrival_Time_Hour'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "745367f6-fb79-47d9-a372-7888054564c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date_of_Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep_Time</th>\n",
       "      <th>Arrival_Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Additional_Info</th>\n",
       "      <th>Price</th>\n",
       "      <th>Arrival_Time_Hour</th>\n",
       "      <th>Dep_Time_Dummy</th>\n",
       "      <th>Dep_Time_Hour</th>\n",
       "      <th>Arrival_Time_Dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>2019-03-24</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR â†’ DEL</td>\n",
       "      <td>22:20</td>\n",
       "      <td>01:10 22 Mar</td>\n",
       "      <td>2:50</td>\n",
       "      <td>0</td>\n",
       "      <td>No info</td>\n",
       "      <td>3897</td>\n",
       "      <td>01:10:00</td>\n",
       "      <td>1900-01-01 22:20:00</td>\n",
       "      <td>22:20:00</td>\n",
       "      <td>1900-01-01 01:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air India</td>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU â†’ IXR â†’ BBI â†’ BLR</td>\n",
       "      <td>05:50</td>\n",
       "      <td>13:15</td>\n",
       "      <td>7:25</td>\n",
       "      <td>2</td>\n",
       "      <td>No info</td>\n",
       "      <td>7662</td>\n",
       "      <td>13:15:00</td>\n",
       "      <td>1900-01-01 05:50:00</td>\n",
       "      <td>05:50:00</td>\n",
       "      <td>1900-01-01 13:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>2019-06-09</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL â†’ LKO â†’ BOM â†’ COK</td>\n",
       "      <td>09:25</td>\n",
       "      <td>04:25 10 Jun</td>\n",
       "      <td>19:00</td>\n",
       "      <td>2</td>\n",
       "      <td>No info</td>\n",
       "      <td>13882</td>\n",
       "      <td>04:25:00</td>\n",
       "      <td>1900-01-01 09:25:00</td>\n",
       "      <td>09:25:00</td>\n",
       "      <td>1900-01-01 04:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>2019-05-12</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU â†’ NAG â†’ BLR</td>\n",
       "      <td>18:05</td>\n",
       "      <td>23:30</td>\n",
       "      <td>5:25</td>\n",
       "      <td>1</td>\n",
       "      <td>No info</td>\n",
       "      <td>6218</td>\n",
       "      <td>23:30:00</td>\n",
       "      <td>1900-01-01 18:05:00</td>\n",
       "      <td>18:05:00</td>\n",
       "      <td>1900-01-01 23:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR â†’ NAG â†’ DEL</td>\n",
       "      <td>16:50</td>\n",
       "      <td>21:35</td>\n",
       "      <td>4:45</td>\n",
       "      <td>1</td>\n",
       "      <td>No info</td>\n",
       "      <td>13302</td>\n",
       "      <td>21:35:00</td>\n",
       "      <td>1900-01-01 16:50:00</td>\n",
       "      <td>16:50:00</td>\n",
       "      <td>1900-01-01 21:35:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Airline Date_of_Journey    Source Destination                  Route  \\\n",
       "0       IndiGo      2019-03-24  Banglore   New Delhi              BLR â†’ DEL   \n",
       "1    Air India      2019-05-01   Kolkata    Banglore  CCU â†’ IXR â†’ BBI â†’ BLR   \n",
       "2  Jet Airways      2019-06-09     Delhi      Cochin  DEL â†’ LKO â†’ BOM â†’ COK   \n",
       "3       IndiGo      2019-05-12   Kolkata    Banglore        CCU â†’ NAG â†’ BLR   \n",
       "4       IndiGo      2019-03-01  Banglore   New Delhi        BLR â†’ NAG â†’ DEL   \n",
       "\n",
       "  Dep_Time  Arrival_Time Duration Total_Stops Additional_Info  Price  \\\n",
       "0    22:20  01:10 22 Mar     2:50           0         No info   3897   \n",
       "1    05:50         13:15     7:25           2         No info   7662   \n",
       "2    09:25  04:25 10 Jun    19:00           2         No info  13882   \n",
       "3    18:05         23:30     5:25           1         No info   6218   \n",
       "4    16:50         21:35     4:45           1         No info  13302   \n",
       "\n",
       "  Arrival_Time_Hour      Dep_Time_Dummy Dep_Time_Hour  Arrival_Time_Dummy  \n",
       "0          01:10:00 1900-01-01 22:20:00      22:20:00 1900-01-01 01:10:00  \n",
       "1          13:15:00 1900-01-01 05:50:00      05:50:00 1900-01-01 13:15:00  \n",
       "2          04:25:00 1900-01-01 09:25:00      09:25:00 1900-01-01 04:25:00  \n",
       "3          23:30:00 1900-01-01 18:05:00      18:05:00 1900-01-01 23:30:00  \n",
       "4          21:35:00 1900-01-01 16:50:00      16:50:00 1900-01-01 21:35:00  "
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4922b5-637c-44bc-a8ff-46244c2c633e",
   "metadata": {},
   "source": [
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·\n",
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·\n",
    "#### 5.4 Converting Total_Stops from string to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "5e5db980-a934-4372-8268-2d215e38ac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['Total_Stops'] = df_copy['Total_Stops'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "a60fd64d-7313-4571-9352-f0807563ce6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 3, 4])"
      ]
     },
     "execution_count": 666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Total_Stops'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116948e5-ce77-49e6-8415-0d43ff654ef6",
   "metadata": {},
   "source": [
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·\n",
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f337a46-004f-4ab6-918b-d2e9a52d9d6f",
   "metadata": {},
   "source": [
    "#### 5.5 Column name changes\n",
    "This step is mainly performed to improve readability and make column names easier to reference in the following steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "d49ddb18-8f40-499a-9a49-a28e220139ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.rename(columns = {\n",
    "    'Date_of_Journey': 'Date of Journey', \n",
    "    'Dep_Time':'Dep Time', \n",
    "    'Arrival_Time':'Arr Time', \n",
    "    'Total_Stops': 'Total Stops',\n",
    "    'Additional_Info':'Additional Info',\n",
    "}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "f485849c-19d5-48fd-ad91-ad946e82a845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date of Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep Time</th>\n",
       "      <th>Arr Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total Stops</th>\n",
       "      <th>Additional Info</th>\n",
       "      <th>Price</th>\n",
       "      <th>Arrival_Time_Hour</th>\n",
       "      <th>Dep_Time_Dummy</th>\n",
       "      <th>Dep_Time_Hour</th>\n",
       "      <th>Arrival_Time_Dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>2019-03-24</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR â†’ DEL</td>\n",
       "      <td>22:20</td>\n",
       "      <td>01:10 22 Mar</td>\n",
       "      <td>2:50</td>\n",
       "      <td>0</td>\n",
       "      <td>No info</td>\n",
       "      <td>3897</td>\n",
       "      <td>01:10:00</td>\n",
       "      <td>1900-01-01 22:20:00</td>\n",
       "      <td>22:20:00</td>\n",
       "      <td>1900-01-01 01:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air India</td>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU â†’ IXR â†’ BBI â†’ BLR</td>\n",
       "      <td>05:50</td>\n",
       "      <td>13:15</td>\n",
       "      <td>7:25</td>\n",
       "      <td>2</td>\n",
       "      <td>No info</td>\n",
       "      <td>7662</td>\n",
       "      <td>13:15:00</td>\n",
       "      <td>1900-01-01 05:50:00</td>\n",
       "      <td>05:50:00</td>\n",
       "      <td>1900-01-01 13:15:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Airline Date of Journey    Source Destination                  Route  \\\n",
       "0     IndiGo      2019-03-24  Banglore   New Delhi              BLR â†’ DEL   \n",
       "1  Air India      2019-05-01   Kolkata    Banglore  CCU â†’ IXR â†’ BBI â†’ BLR   \n",
       "\n",
       "  Dep Time      Arr Time Duration  Total Stops Additional Info  Price  \\\n",
       "0    22:20  01:10 22 Mar     2:50            0         No info   3897   \n",
       "1    05:50         13:15     7:25            2         No info   7662   \n",
       "\n",
       "  Arrival_Time_Hour      Dep_Time_Dummy Dep_Time_Hour  Arrival_Time_Dummy  \n",
       "0          01:10:00 1900-01-01 22:20:00      22:20:00 1900-01-01 01:10:00  \n",
       "1          13:15:00 1900-01-01 05:50:00      05:50:00 1900-01-01 13:15:00  "
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f6bcfe-144c-46df-9b94-34b9c67b09a4",
   "metadata": {},
   "source": [
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·\n",
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50ea517-f9dc-442e-b7c0-428b6ceaf365",
   "metadata": {},
   "source": [
    "### 6 CONCISTENCY CHECK ACROSS COLUMNS\n",
    "It's important to make sure that there are no inconsistent values in the features, otherwise operations and modelling couldn't work properly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13089b78-560b-44f4-83c0-84f57a788379",
   "metadata": {},
   "source": [
    "#### 6.1 Consistency check on Price column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "47f720c9-434c-497f-8d86-1fb7e6043670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date of Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep Time</th>\n",
       "      <th>Arr Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total Stops</th>\n",
       "      <th>Additional Info</th>\n",
       "      <th>Price</th>\n",
       "      <th>Arrival_Time_Hour</th>\n",
       "      <th>Dep_Time_Dummy</th>\n",
       "      <th>Dep_Time_Hour</th>\n",
       "      <th>Arrival_Time_Dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Airline, Date of Journey, Source, Destination, Route, Dep Time, Arr Time, Duration, Total Stops, Additional Info, Price, Arrival_Time_Hour, Dep_Time_Dummy, Dep_Time_Hour, Arrival_Time_Dummy]\n",
       "Index: []"
      ]
     },
     "execution_count": 677,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for negative prices\n",
    "df_copy[df_copy['Price']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "cb2d1a4c-07ae-4a0f-8192-34a7a661d337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10462.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9026.790289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4624.849541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1759.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5224.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8266.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12344.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>79512.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Price\n",
       "count  10462.000000\n",
       "mean    9026.790289\n",
       "std     4624.849541\n",
       "min     1759.000000\n",
       "25%     5224.000000\n",
       "50%     8266.000000\n",
       "75%    12344.750000\n",
       "max    79512.000000"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[['Price']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "6c87c176-8d4a-4664-ba06-7f399aa1692c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 15)"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[(df_copy['Price']>=50000) & (df_copy['Price']<=79512)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "1e9538f4-80a3-4563-9592-b45991f0b0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10462, 15)"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022bfb52-03da-4a36-b46b-e389b9a30770",
   "metadata": {},
   "source": [
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "df840005-f96a-4c37-975c-fdec487aef18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        True\n",
       "1        True\n",
       "2        True\n",
       "3        True\n",
       "4        True\n",
       "         ... \n",
       "10678    True\n",
       "10679    True\n",
       "10680    True\n",
       "10681    True\n",
       "10682    True\n",
       "Name: Price, Length: 10462, dtype: bool"
      ]
     },
     "execution_count": 686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking if all values in Price are integers \n",
    "(df_copy['Price'] % 1 == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "445121f0-99a4-4efc-b7ef-c0dbcf1dcf21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10462,)"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_copy['Price'] % 1 == 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "d6158042-7cba-4cee-8f72-2ca6dc28bbe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_copy['Price'] % 1 == 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "323f9621-c8b9-478f-a537-d6ddf512dd89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Price'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "3efa441e-9473-430f-974f-630cd97fa318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Price'].dtype == 'float64'\n",
    "\n",
    "#or, if we wanted to check the amount of records with dtype = float\n",
    "\n",
    "# (df_copy['Price'] % 1 != 0).all()\n",
    "# (df_copy['Price'] % 1 != 0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d51b1d-eaa3-4803-83a3-fe8d0c07631f",
   "metadata": {},
   "source": [
    "#### Insights\n",
    "The records in Price are all positive!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b4998d-03a6-4388-b034-41504810fa58",
   "metadata": {},
   "source": [
    "NOTE: The last checks were reduntant as we know the dtype from df_copy.info().  \n",
    "If there were a mix of int and float, df.info() would return float, in which case it could be useful to check the number of float and integers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00e5350-5756-4487-b8d5-48a342d3b800",
   "metadata": {},
   "source": [
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·\n",
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7362003f-55af-47ab-8ce2-42e9f8814665",
   "metadata": {},
   "source": [
    "#### 6.2 Consistency check on Source and Destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "f904912e-e777-4afa-9e66-f3f365e37817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date of Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep Time</th>\n",
       "      <th>Arr Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total Stops</th>\n",
       "      <th>Additional Info</th>\n",
       "      <th>Price</th>\n",
       "      <th>Arrival_Time_Hour</th>\n",
       "      <th>Dep_Time_Dummy</th>\n",
       "      <th>Dep_Time_Hour</th>\n",
       "      <th>Arrival_Time_Dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Airline, Date of Journey, Source, Destination, Route, Dep Time, Arr Time, Duration, Total Stops, Additional Info, Price, Arrival_Time_Hour, Dep_Time_Dummy, Dep_Time_Hour, Arrival_Time_Dummy]\n",
       "Index: []"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Source']==df_copy['Destination']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cb8649-b970-4d34-98b1-5073215012b3",
   "metadata": {},
   "source": [
    "#### Insights\n",
    "No inconcistencies were found between Source and Destination columns as there are no identical destination for each source and viceversa!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80350437-1bb2-4b88-aa31-0842ca595902",
   "metadata": {},
   "source": [
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·\n",
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·\n",
    "#### 6.3 Consistency check on Duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6558fe1-214f-421e-96d9-8c1cc5755e42",
   "metadata": {},
   "source": [
    "#### 6.3.1 Checking possible negative Durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "id": "6a889580-a236-4e51-953f-a59e5239830f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date of Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep Time</th>\n",
       "      <th>Arr Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total Stops</th>\n",
       "      <th>Additional Info</th>\n",
       "      <th>Price</th>\n",
       "      <th>Arrival_Time_Hour</th>\n",
       "      <th>Dep_Time_Dummy</th>\n",
       "      <th>Dep_Time_Hour</th>\n",
       "      <th>Arrival_Time_Dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Airline, Date of Journey, Source, Destination, Route, Dep Time, Arr Time, Duration, Total Stops, Additional Info, Price, Arrival_Time_Hour, Dep_Time_Dummy, Dep_Time_Hour, Arrival_Time_Dummy]\n",
       "Index: []"
      ]
     },
     "execution_count": 705,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[(df_copy['Duration'].str.replace(':','').astype(int))<0]\n",
    "\n",
    "#or, I could have created a new column and ran the check on it (less efficient)\n",
    "\n",
    "# df_copy['Duration']=df_copy['Duration'].str.replace(':','').astype(int)\n",
    "# df_copy[df_copy['Duration']<0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62eda28-10a3-4a94-86f9-b3b2b6018cb1",
   "metadata": {},
   "source": [
    "#### Insights\n",
    "Records in duration are all positive!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b6e744-e57e-4492-b192-112f5183dd2d",
   "metadata": {},
   "source": [
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbd5846-ec7a-452c-9ef0-aa84d5e0cdbb",
   "metadata": {},
   "source": [
    "#### 6.3.2 Checking for extremes durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "id": "58b9d1cf-4800-49fe-9036-2bac3ad71890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gs/d24257s15q1bzbn_vyvcxhb00000gp/T/ipykernel_96221/3095469934.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(df_copy['Duration']).min()\n"
     ]
    },
    {
     "ename": "OutOfBoundsDatetime",
     "evalue": "Out of bounds nanosecond timestamp: 21:5, at position 7",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32mconversion.pyx:326\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion._TSObject.ensure_reso\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mnp_datetime.pyx:683\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.np_datetime.convert_reso\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOverflowError\u001b[0m: result would overflow",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOutOfBoundsDatetime\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[710], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pd\u001b[38;5;241m.\u001b[39mto_datetime(df_copy[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDuration\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mmin()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/tools/datetimes.py:1063\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1061\u001b[0m             result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, ABCSeries):\n\u001b[0;32m-> 1063\u001b[0m     cache_array \u001b[38;5;241m=\u001b[39m _maybe_cache(arg, \u001b[38;5;28mformat\u001b[39m, cache, convert_listlike)\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache_array\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m   1065\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/tools/datetimes.py:247\u001b[0m, in \u001b[0;36m_maybe_cache\u001b[0;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[1;32m    245\u001b[0m unique_dates \u001b[38;5;241m=\u001b[39m unique(arg)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dates) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(arg):\n\u001b[0;32m--> 247\u001b[0m     cache_dates \u001b[38;5;241m=\u001b[39m convert_listlike(unique_dates, \u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;66;03m# GH#45319\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/tools/datetimes.py:435\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[38;5;28mformat\u001b[39m, exact, errors)\n\u001b[0;32m--> 435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64(\n\u001b[1;32m    436\u001b[0m     arg,\n\u001b[1;32m    437\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[1;32m    438\u001b[0m     yearfirst\u001b[38;5;241m=\u001b[39myearfirst,\n\u001b[1;32m    439\u001b[0m     utc\u001b[38;5;241m=\u001b[39mutc,\n\u001b[1;32m    440\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    441\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    442\u001b[0m )\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n\u001b[1;32m    447\u001b[0m     out_unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arrays/datetimes.py:2398\u001b[0m, in \u001b[0;36mobjects_to_datetime64\u001b[0;34m(data, dayfirst, yearfirst, utc, errors, allow_object, out_unit)\u001b[0m\n\u001b[1;32m   2395\u001b[0m \u001b[38;5;66;03m# if str-dtype, convert\u001b[39;00m\n\u001b[1;32m   2396\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(data, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mobject_)\n\u001b[0;32m-> 2398\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m tslib\u001b[38;5;241m.\u001b[39marray_to_datetime(\n\u001b[1;32m   2399\u001b[0m     data,\n\u001b[1;32m   2400\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m   2401\u001b[0m     utc\u001b[38;5;241m=\u001b[39mutc,\n\u001b[1;32m   2402\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[1;32m   2403\u001b[0m     yearfirst\u001b[38;5;241m=\u001b[39myearfirst,\n\u001b[1;32m   2404\u001b[0m     creso\u001b[38;5;241m=\u001b[39mabbrev_to_npy_unit(out_unit),\n\u001b[1;32m   2405\u001b[0m )\n\u001b[1;32m   2407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2408\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m   2409\u001b[0m     \u001b[38;5;66;03m#  is in UTC\u001b[39;00m\n\u001b[1;32m   2410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result, tz_parsed\n",
      "File \u001b[0;32mtslib.pyx:414\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtslib.pyx:596\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtslib.pyx:571\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mconversion.pyx:332\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion._TSObject.ensure_reso\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOutOfBoundsDatetime\u001b[0m: Out of bounds nanosecond timestamp: 21:5, at position 7"
     ]
    }
   ],
   "source": [
    "pd.to_datetime(df_copy['Duration']).min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01424b78-8dfa-4300-877c-aaf053fcb25b",
   "metadata": {},
   "source": [
    "The previous check has immediately highlitghted an inconcistency in the time format of Duration where 21h 5m has been converted to 21:5 which is not a proper format for time. There might be more entries that have been converted to such format. This kind of problems can be easily fixed durin the FE process by separating the plitting the column into hours and minutes. \n",
    "For the sake completeness we'll address them in this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "id": "66eaa21a-23f5-4ca6-ae59-59035c6e771c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date of Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep Time</th>\n",
       "      <th>Arr Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total Stops</th>\n",
       "      <th>Additional Info</th>\n",
       "      <th>Price</th>\n",
       "      <th>Arrival_Time_Hour</th>\n",
       "      <th>Dep_Time_Dummy</th>\n",
       "      <th>Dep_Time_Hour</th>\n",
       "      <th>Arrival_Time_Dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR â†’ BOM â†’ DEL</td>\n",
       "      <td>08:00</td>\n",
       "      <td>05:05 02 Mar</td>\n",
       "      <td>21:5</td>\n",
       "      <td>1</td>\n",
       "      <td>No info</td>\n",
       "      <td>22270</td>\n",
       "      <td>05:05:00</td>\n",
       "      <td>1900-01-01 08:00:00</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>1900-01-01 05:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Multiple carriers</td>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL â†’ HYD â†’ COK</td>\n",
       "      <td>07:05</td>\n",
       "      <td>18:10</td>\n",
       "      <td>11:5</td>\n",
       "      <td>1</td>\n",
       "      <td>No info</td>\n",
       "      <td>9646</td>\n",
       "      <td>18:10:00</td>\n",
       "      <td>1900-01-01 07:05:00</td>\n",
       "      <td>07:05:00</td>\n",
       "      <td>1900-01-01 18:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>2019-05-18</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL â†’ BOM â†’ COK</td>\n",
       "      <td>20:55</td>\n",
       "      <td>19:00 19 May</td>\n",
       "      <td>22:5</td>\n",
       "      <td>1</td>\n",
       "      <td>In-flight meal not included</td>\n",
       "      <td>12373</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>1900-01-01 20:55:00</td>\n",
       "      <td>20:55:00</td>\n",
       "      <td>1900-01-01 19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Air India</td>\n",
       "      <td>2019-05-15</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU â†’ HYD â†’ BLR</td>\n",
       "      <td>19:00</td>\n",
       "      <td>11:05 16 May</td>\n",
       "      <td>16:5</td>\n",
       "      <td>1</td>\n",
       "      <td>No info</td>\n",
       "      <td>6117</td>\n",
       "      <td>11:05:00</td>\n",
       "      <td>1900-01-01 19:00:00</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>1900-01-01 11:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Air India</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR â†’ BOM â†’ AMD â†’ DEL</td>\n",
       "      <td>08:50</td>\n",
       "      <td>23:55</td>\n",
       "      <td>15:5</td>\n",
       "      <td>2</td>\n",
       "      <td>No info</td>\n",
       "      <td>17345</td>\n",
       "      <td>23:55:00</td>\n",
       "      <td>1900-01-01 08:50:00</td>\n",
       "      <td>08:50:00</td>\n",
       "      <td>1900-01-01 23:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10592</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU â†’ BOM â†’ BLR</td>\n",
       "      <td>18:55</td>\n",
       "      <td>12:00 22 May</td>\n",
       "      <td>17:5</td>\n",
       "      <td>1</td>\n",
       "      <td>In-flight meal not included</td>\n",
       "      <td>10844</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>1900-01-01 18:55:00</td>\n",
       "      <td>18:55:00</td>\n",
       "      <td>1900-01-01 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10613</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>BLR â†’ DEL</td>\n",
       "      <td>18:55</td>\n",
       "      <td>22:00</td>\n",
       "      <td>3:5</td>\n",
       "      <td>0</td>\n",
       "      <td>No info</td>\n",
       "      <td>8016</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>1900-01-01 18:55:00</td>\n",
       "      <td>18:55:00</td>\n",
       "      <td>1900-01-01 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10629</th>\n",
       "      <td>Multiple carriers</td>\n",
       "      <td>2019-03-03</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL â†’ HYD â†’ COK</td>\n",
       "      <td>07:05</td>\n",
       "      <td>16:10</td>\n",
       "      <td>9:5</td>\n",
       "      <td>1</td>\n",
       "      <td>No info</td>\n",
       "      <td>7905</td>\n",
       "      <td>16:10:00</td>\n",
       "      <td>1900-01-01 07:05:00</td>\n",
       "      <td>07:05:00</td>\n",
       "      <td>1900-01-01 16:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10637</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>2019-04-24</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>BLR â†’ DEL</td>\n",
       "      <td>18:55</td>\n",
       "      <td>22:00</td>\n",
       "      <td>3:5</td>\n",
       "      <td>0</td>\n",
       "      <td>No info</td>\n",
       "      <td>7229</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>1900-01-01 18:55:00</td>\n",
       "      <td>18:55:00</td>\n",
       "      <td>1900-01-01 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10663</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>2019-06-06</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL â†’ JAI â†’ BOM â†’ COK</td>\n",
       "      <td>19:30</td>\n",
       "      <td>12:35 07 Jun</td>\n",
       "      <td>17:5</td>\n",
       "      <td>2</td>\n",
       "      <td>In-flight meal not included</td>\n",
       "      <td>11733</td>\n",
       "      <td>12:35:00</td>\n",
       "      <td>1900-01-01 19:30:00</td>\n",
       "      <td>19:30:00</td>\n",
       "      <td>1900-01-01 12:35:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>619 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Airline Date of Journey    Source Destination  \\\n",
       "7            Jet Airways      2019-03-01  Banglore   New Delhi   \n",
       "40     Multiple carriers      2019-05-21     Delhi      Cochin   \n",
       "42           Jet Airways      2019-05-18     Delhi      Cochin   \n",
       "48             Air India      2019-05-15   Kolkata    Banglore   \n",
       "56             Air India      2019-03-01  Banglore   New Delhi   \n",
       "...                  ...             ...       ...         ...   \n",
       "10592        Jet Airways      2019-05-21   Kolkata    Banglore   \n",
       "10613        Jet Airways      2019-06-03  Banglore       Delhi   \n",
       "10629  Multiple carriers      2019-03-03     Delhi      Cochin   \n",
       "10637        Jet Airways      2019-04-24  Banglore       Delhi   \n",
       "10663        Jet Airways      2019-06-06     Delhi      Cochin   \n",
       "\n",
       "                       Route Dep Time      Arr Time Duration  Total Stops  \\\n",
       "7            BLR â†’ BOM â†’ DEL    08:00  05:05 02 Mar     21:5            1   \n",
       "40           DEL â†’ HYD â†’ COK    07:05         18:10     11:5            1   \n",
       "42           DEL â†’ BOM â†’ COK    20:55  19:00 19 May     22:5            1   \n",
       "48           CCU â†’ HYD â†’ BLR    19:00  11:05 16 May     16:5            1   \n",
       "56     BLR â†’ BOM â†’ AMD â†’ DEL    08:50         23:55     15:5            2   \n",
       "...                      ...      ...           ...      ...          ...   \n",
       "10592        CCU â†’ BOM â†’ BLR    18:55  12:00 22 May     17:5            1   \n",
       "10613              BLR â†’ DEL    18:55         22:00      3:5            0   \n",
       "10629        DEL â†’ HYD â†’ COK    07:05         16:10      9:5            1   \n",
       "10637              BLR â†’ DEL    18:55         22:00      3:5            0   \n",
       "10663  DEL â†’ JAI â†’ BOM â†’ COK    19:30  12:35 07 Jun     17:5            2   \n",
       "\n",
       "                   Additional Info  Price Arrival_Time_Hour  \\\n",
       "7                          No info  22270          05:05:00   \n",
       "40                         No info   9646          18:10:00   \n",
       "42     In-flight meal not included  12373          19:00:00   \n",
       "48                         No info   6117          11:05:00   \n",
       "56                         No info  17345          23:55:00   \n",
       "...                            ...    ...               ...   \n",
       "10592  In-flight meal not included  10844          12:00:00   \n",
       "10613                      No info   8016          22:00:00   \n",
       "10629                      No info   7905          16:10:00   \n",
       "10637                      No info   7229          22:00:00   \n",
       "10663  In-flight meal not included  11733          12:35:00   \n",
       "\n",
       "           Dep_Time_Dummy Dep_Time_Hour  Arrival_Time_Dummy  \n",
       "7     1900-01-01 08:00:00      08:00:00 1900-01-01 05:05:00  \n",
       "40    1900-01-01 07:05:00      07:05:00 1900-01-01 18:10:00  \n",
       "42    1900-01-01 20:55:00      20:55:00 1900-01-01 19:00:00  \n",
       "48    1900-01-01 19:00:00      19:00:00 1900-01-01 11:05:00  \n",
       "56    1900-01-01 08:50:00      08:50:00 1900-01-01 23:55:00  \n",
       "...                   ...           ...                 ...  \n",
       "10592 1900-01-01 18:55:00      18:55:00 1900-01-01 12:00:00  \n",
       "10613 1900-01-01 18:55:00      18:55:00 1900-01-01 22:00:00  \n",
       "10629 1900-01-01 07:05:00      07:05:00 1900-01-01 16:10:00  \n",
       "10637 1900-01-01 18:55:00      18:55:00 1900-01-01 22:00:00  \n",
       "10663 1900-01-01 19:30:00      19:30:00 1900-01-01 12:35:00  \n",
       "\n",
       "[619 rows x 15 columns]"
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for the number of record with strings that contain only 4 digits (2 numbers then : and another number)\n",
    "df_copy[df_copy['Duration'].str.split(':').str[1].str.len()==1] #.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabc3b8c-2459-4744-92a8-d30adb5aa526",
   "metadata": {},
   "source": [
    "We have 619 record that match the format hh:m\n",
    "\n",
    "In order to check if Duration is Consistent with the numbers of stops we must convert such records into hh:mm, making sure that the first minute is m=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "id": "0f156a39-c835-405f-8f6c-50c6ffe5a56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['Duration'] = df_copy['Duration'].apply(lambda x: x if ':' not in x else x.split(':')[0] + ':' + x.split(':')[1].zfill(2))\n",
    "\n",
    "\n",
    "#or (my version)\n",
    "\n",
    "#df_copy['Duration'].apply(lambda x: x if ':' not in x else x.split(':')[0]+ ':0'+ x.split(':')[1] if len(x.split(':')[1])==1 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9fe5c7-e8dc-4f0b-8ebe-a5285da6d9bc",
   "metadata": {},
   "source": [
    "NOTE: .zfill(2) pads (=adds extra character) the string is referring to with a 0 (always on the left) if itâ€™s less than 2 digits â†’ '5' â†’ '05'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "id": "5a6ebca3-72e3-4eed-a970-3a0d297810f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date of Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep Time</th>\n",
       "      <th>Arr Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total Stops</th>\n",
       "      <th>Additional Info</th>\n",
       "      <th>Price</th>\n",
       "      <th>Arrival_Time_Hour</th>\n",
       "      <th>Dep_Time_Dummy</th>\n",
       "      <th>Dep_Time_Hour</th>\n",
       "      <th>Arrival_Time_Dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>2019-03-24</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR â†’ DEL</td>\n",
       "      <td>22:20</td>\n",
       "      <td>01:10 22 Mar</td>\n",
       "      <td>2:50</td>\n",
       "      <td>0</td>\n",
       "      <td>No info</td>\n",
       "      <td>3897</td>\n",
       "      <td>01:10:00</td>\n",
       "      <td>1900-01-01 22:20:00</td>\n",
       "      <td>22:20:00</td>\n",
       "      <td>1900-01-01 01:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air India</td>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU â†’ IXR â†’ BBI â†’ BLR</td>\n",
       "      <td>05:50</td>\n",
       "      <td>13:15</td>\n",
       "      <td>7:25</td>\n",
       "      <td>2</td>\n",
       "      <td>No info</td>\n",
       "      <td>7662</td>\n",
       "      <td>13:15:00</td>\n",
       "      <td>1900-01-01 05:50:00</td>\n",
       "      <td>05:50:00</td>\n",
       "      <td>1900-01-01 13:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>2019-06-09</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL â†’ LKO â†’ BOM â†’ COK</td>\n",
       "      <td>09:25</td>\n",
       "      <td>04:25 10 Jun</td>\n",
       "      <td>19:00</td>\n",
       "      <td>2</td>\n",
       "      <td>No info</td>\n",
       "      <td>13882</td>\n",
       "      <td>04:25:00</td>\n",
       "      <td>1900-01-01 09:25:00</td>\n",
       "      <td>09:25:00</td>\n",
       "      <td>1900-01-01 04:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>2019-05-12</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU â†’ NAG â†’ BLR</td>\n",
       "      <td>18:05</td>\n",
       "      <td>23:30</td>\n",
       "      <td>5:25</td>\n",
       "      <td>1</td>\n",
       "      <td>No info</td>\n",
       "      <td>6218</td>\n",
       "      <td>23:30:00</td>\n",
       "      <td>1900-01-01 18:05:00</td>\n",
       "      <td>18:05:00</td>\n",
       "      <td>1900-01-01 23:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR â†’ NAG â†’ DEL</td>\n",
       "      <td>16:50</td>\n",
       "      <td>21:35</td>\n",
       "      <td>4:45</td>\n",
       "      <td>1</td>\n",
       "      <td>No info</td>\n",
       "      <td>13302</td>\n",
       "      <td>21:35:00</td>\n",
       "      <td>1900-01-01 16:50:00</td>\n",
       "      <td>16:50:00</td>\n",
       "      <td>1900-01-01 21:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SpiceJet</td>\n",
       "      <td>2019-06-24</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU â†’ BLR</td>\n",
       "      <td>09:00</td>\n",
       "      <td>11:25</td>\n",
       "      <td>2:25</td>\n",
       "      <td>0</td>\n",
       "      <td>No info</td>\n",
       "      <td>3873</td>\n",
       "      <td>11:25:00</td>\n",
       "      <td>1900-01-01 09:00:00</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>1900-01-01 11:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR â†’ BOM â†’ DEL</td>\n",
       "      <td>18:55</td>\n",
       "      <td>10:25 13 Mar</td>\n",
       "      <td>15:30</td>\n",
       "      <td>1</td>\n",
       "      <td>In-flight meal not included</td>\n",
       "      <td>11087</td>\n",
       "      <td>10:25:00</td>\n",
       "      <td>1900-01-01 18:55:00</td>\n",
       "      <td>18:55:00</td>\n",
       "      <td>1900-01-01 10:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR â†’ BOM â†’ DEL</td>\n",
       "      <td>08:00</td>\n",
       "      <td>05:05 02 Mar</td>\n",
       "      <td>21:05</td>\n",
       "      <td>1</td>\n",
       "      <td>No info</td>\n",
       "      <td>22270</td>\n",
       "      <td>05:05:00</td>\n",
       "      <td>1900-01-01 08:00:00</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>1900-01-01 05:05:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Airline Date of Journey    Source Destination                  Route  \\\n",
       "0       IndiGo      2019-03-24  Banglore   New Delhi              BLR â†’ DEL   \n",
       "1    Air India      2019-05-01   Kolkata    Banglore  CCU â†’ IXR â†’ BBI â†’ BLR   \n",
       "2  Jet Airways      2019-06-09     Delhi      Cochin  DEL â†’ LKO â†’ BOM â†’ COK   \n",
       "3       IndiGo      2019-05-12   Kolkata    Banglore        CCU â†’ NAG â†’ BLR   \n",
       "4       IndiGo      2019-03-01  Banglore   New Delhi        BLR â†’ NAG â†’ DEL   \n",
       "5     SpiceJet      2019-06-24   Kolkata    Banglore              CCU â†’ BLR   \n",
       "6  Jet Airways      2019-03-12  Banglore   New Delhi        BLR â†’ BOM â†’ DEL   \n",
       "7  Jet Airways      2019-03-01  Banglore   New Delhi        BLR â†’ BOM â†’ DEL   \n",
       "\n",
       "  Dep Time      Arr Time Duration  Total Stops              Additional Info  \\\n",
       "0    22:20  01:10 22 Mar     2:50            0                      No info   \n",
       "1    05:50         13:15     7:25            2                      No info   \n",
       "2    09:25  04:25 10 Jun    19:00            2                      No info   \n",
       "3    18:05         23:30     5:25            1                      No info   \n",
       "4    16:50         21:35     4:45            1                      No info   \n",
       "5    09:00         11:25     2:25            0                      No info   \n",
       "6    18:55  10:25 13 Mar    15:30            1  In-flight meal not included   \n",
       "7    08:00  05:05 02 Mar    21:05            1                      No info   \n",
       "\n",
       "   Price Arrival_Time_Hour      Dep_Time_Dummy Dep_Time_Hour  \\\n",
       "0   3897          01:10:00 1900-01-01 22:20:00      22:20:00   \n",
       "1   7662          13:15:00 1900-01-01 05:50:00      05:50:00   \n",
       "2  13882          04:25:00 1900-01-01 09:25:00      09:25:00   \n",
       "3   6218          23:30:00 1900-01-01 18:05:00      18:05:00   \n",
       "4  13302          21:35:00 1900-01-01 16:50:00      16:50:00   \n",
       "5   3873          11:25:00 1900-01-01 09:00:00      09:00:00   \n",
       "6  11087          10:25:00 1900-01-01 18:55:00      18:55:00   \n",
       "7  22270          05:05:00 1900-01-01 08:00:00      08:00:00   \n",
       "\n",
       "   Arrival_Time_Dummy  \n",
       "0 1900-01-01 01:10:00  \n",
       "1 1900-01-01 13:15:00  \n",
       "2 1900-01-01 04:25:00  \n",
       "3 1900-01-01 23:30:00  \n",
       "4 1900-01-01 21:35:00  \n",
       "5 1900-01-01 11:25:00  \n",
       "6 1900-01-01 10:25:00  \n",
       "7 1900-01-01 05:05:00  "
      ]
     },
     "execution_count": 719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899e2979-15d6-4ada-b9db-41b2778a43b3",
   "metadata": {},
   "source": [
    "Now we can turn the record in the Duration column into float so to perform comparison among them, including finding the min and the max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "id": "c713b613-a000-4295-a565-80e47f466689",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['Duration_todrop']=df_copy['Duration'].str.replace(':','.').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "id": "1eb56d67-2a4c-4368-8663-0b81a5119f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.15"
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Duration_todrop'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "id": "8e676b3a-8138-4898-8ca7-6cdb9c1dd8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.4"
      ]
     },
     "execution_count": 726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Duration_todrop'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "id": "9459cc55-234b-46a9-b92a-9de072402ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration_todrop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10462.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.308765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.356638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>47.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Duration_todrop\n",
       "count     10462.000000\n",
       "mean         10.308765\n",
       "std           8.356638\n",
       "min           1.150000\n",
       "25%           2.500000\n",
       "50%           8.250000\n",
       "75%          15.100000\n",
       "max          47.400000"
      ]
     },
     "execution_count": 728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[['Duration_todrop']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "id": "e841361b-8ff0-4ed0-9542-374433fa88d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duration_todrop</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47.40</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47.00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42.45</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42.05</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41.20</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40.20</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39.05</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38.35</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38.20</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38.15</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count\n",
       "Duration_todrop       \n",
       "47.40                1\n",
       "47.00                1\n",
       "42.45                1\n",
       "42.05                1\n",
       "41.20                1\n",
       "40.20                1\n",
       "39.05                1\n",
       "38.35                4\n",
       "38.20                4\n",
       "38.15               12"
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick check for extreme durations \n",
    "df_copy['Duration_todrop'].value_counts(ascending = False).sort_index(ascending = False).head(10).to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137c121e-be7a-40a7-b5d6-a8ef0ffaeb09",
   "metadata": {},
   "source": [
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e1800d-d0e4-4e5c-bcde-8f858894fd27",
   "metadata": {},
   "source": [
    "#### NOTE - important Error:\n",
    "From a previous analysis emerged a record for a flight with a duration of 5 minutes.  \n",
    "During the convertion of Duration from the orignal format ('xx'H 'yy'H), all the entries with no hour have been changed into hours. This happened because the convertion didn't take into consideration datapoints lacking the hour. Though this is not a major issues since a 5 minutes flight is certainly impossible, it's conceptually wrong and could lead to inaccurate data since 5 minutes turned into 5 hours.\n",
    "\n",
    "We are now going to run a second datacleaning for the Duration column from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "id": "ead7a762-928d-4bf2-8231-6c912a65b152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date of Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep Time</th>\n",
       "      <th>Arr Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total Stops</th>\n",
       "      <th>Additional Info</th>\n",
       "      <th>Price</th>\n",
       "      <th>Arrival_Time_Hour</th>\n",
       "      <th>Dep_Time_Dummy</th>\n",
       "      <th>Dep_Time_Hour</th>\n",
       "      <th>Arrival_Time_Dummy</th>\n",
       "      <th>Duration_todrop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Airline, Date of Journey, Source, Destination, Route, Dep Time, Arr Time, Duration, Total Stops, Additional Info, Price, Arrival_Time_Hour, Dep_Time_Dummy, Dep_Time_Hour, Arrival_Time_Dummy, Duration_todrop]\n",
       "Index: []"
      ]
     },
     "execution_count": 734,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy[df_copy['Duration']=='5m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "id": "09f337ba-766e-4d71-9dee-fbde872e1266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date of Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep Time</th>\n",
       "      <th>Arr Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total Stops</th>\n",
       "      <th>Additional Info</th>\n",
       "      <th>Price</th>\n",
       "      <th>Arrival_Time_Hour</th>\n",
       "      <th>Dep_Time_Dummy</th>\n",
       "      <th>Dep_Time_Hour</th>\n",
       "      <th>Arrival_Time_Dummy</th>\n",
       "      <th>Duration_todrop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6474</th>\n",
       "      <td>Air India</td>\n",
       "      <td>2019-03-06</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>BOM â†’ GOI â†’ PNQ â†’ HYD</td>\n",
       "      <td>16:50</td>\n",
       "      <td>16:55</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>No info</td>\n",
       "      <td>17327</td>\n",
       "      <td>16:55:00</td>\n",
       "      <td>1900-01-01 16:50:00</td>\n",
       "      <td>16:50:00</td>\n",
       "      <td>1900-01-01 16:55:00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Airline Date of Journey  Source Destination                  Route  \\\n",
       "6474  Air India      2019-03-06  Mumbai   Hyderabad  BOM â†’ GOI â†’ PNQ â†’ HYD   \n",
       "\n",
       "     Dep Time Arr Time Duration  Total Stops Additional Info  Price  \\\n",
       "6474    16:50    16:55        5            2         No info  17327   \n",
       "\n",
       "     Arrival_Time_Hour      Dep_Time_Dummy Dep_Time_Hour  Arrival_Time_Dummy  \\\n",
       "6474          16:55:00 1900-01-01 16:50:00      16:50:00 1900-01-01 16:55:00   \n",
       "\n",
       "      Duration_todrop  \n",
       "6474              5.0  "
      ]
     },
     "execution_count": 736,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.loc[[6474]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "id": "1ab7f29f-0f1b-4f7a-a1c8-ebb776999804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2:50', '7:25', '19:00', '5:25', '4:45', '2:25', '15:30', '21:05',\n",
       "       '25:30', '7:50', '13:15', '2:35', '2:15', '12:10', '26:35', '4:30',\n",
       "       '22:35', '23:00', '20:35', '5:10', '15:20', '2:55', '13:20',\n",
       "       '15:10', '5:45', '5:55', '13:25', '22:00', '5:30', '10:25', '5:15',\n",
       "       '2:30', '6:15', '11:55', '11:05', '8:30', '22:05', '2:45', '12:00',\n",
       "       '16:05', '19:55', '3:15', '25:20', '3:00', '16:15', '15:05',\n",
       "       '6:30', '25:05', '12:25', '27:20', '10:15', '10:30', '1:30',\n",
       "       '1:25', '26:30', '7:20', '13:30', '5:00', '19:05', '14:50', '2:40',\n",
       "       '22:10', '9:35', '10:00', '21:20', '18:45', '12:20', '18:00',\n",
       "       '9:15', '17:30', '16:35', '12:15', '7:30', '24:00', '8:55', '7:10',\n",
       "       '14:30', '30:20', '15:00', '12:45', '10:10', '15:25', '14:05',\n",
       "       '20:15', '23:10', '18:10', '16:00', '2:20', '8:00', '16:55',\n",
       "       '3:10', '14:00', '23:50', '21:40', '21:15', '10:50', '8:15',\n",
       "       '8:35', '11:50', '27:35', '8:25', '20:55', '4:50', '8:10', '24:25',\n",
       "       '23:35', '25:45', '26:10', '28:50', '25:15', '9:20', '9:10',\n",
       "       '3:05', '11:30', '9:30', '17:35', '5:05', '25:50', '20:00',\n",
       "       '13:00', '18:25', '24:10', '4:55', '25:35', '6:20', '18:40',\n",
       "       '19:25', '29:20', '9:05', '10:45', '11:40', '22:55', '37:25',\n",
       "       '25:40', '13:55', '8:40', '23:30', '12:35', '24:15', '1:20',\n",
       "       '11:00', '11:15', '14:35', '12:55', '9:00', '7:40', '11:45',\n",
       "       '24:55', '17:05', '29:55', '22:15', '14:40', '7:15', '20:10',\n",
       "       '20:45', '27:00', '24:30', '20:25', '5:35', '14:45', '5:40',\n",
       "       '4:05', '15:55', '7:45', '28:20', '4:20', '3:40', '8:50', '23:45',\n",
       "       '24:45', '21:35', '8:05', '6:25', '15:50', '26:25', '24:50',\n",
       "       '26:00', '23:05', '7:55', '26:20', '23:15', '5:20', '4:00', '9:45',\n",
       "       '8:20', '17:25', '7:05', '34:05', '6:05', '5:50', '7:00', '4:25',\n",
       "       '13:45', '19:15', '22:30', '16:25', '13:50', '27:05', '28:10',\n",
       "       '4:40', '15:40', '4:35', '18:30', '38:15', '6:35', '12:30',\n",
       "       '11:20', '7:35', '29:35', '26:55', '23:40', '12:50', '9:50',\n",
       "       '21:55', '10:55', '21:10', '20:40', '30:00', '13:10', '8:45',\n",
       "       '6:10', '17:45', '21:45', '3:55', '17:20', '30:30', '21:25',\n",
       "       '12:40', '24:35', '19:10', '22:40', '14:55', '21:00', '6:45',\n",
       "       '28:40', '9:40', '16:40', '16:20', '16:45', '1:15', '6:55',\n",
       "       '11:25', '14:20', '12:05', '24:05', '28:15', '17:50', '20:20',\n",
       "       '28:05', '10:20', '14:15', '35:15', '35:35', '26:40', '28:00',\n",
       "       '14:25', '13:05', '37:20', '36:10', '25:55', '35:05', '19:45',\n",
       "       '27:55', '47:00', '10:35', '1:35', '16:10', '38:20', '6:00',\n",
       "       '16:50', '14:10', '23:20', '17:40', '11:35', '18:20', '6:40',\n",
       "       '30:55', '24:40', '29:50', '28:25', '17:15', '22:45', '25:25',\n",
       "       '21:50', '33:15', '30:15', '3:35', '27:40', '30:25', '18:50',\n",
       "       '27:45', '15:15', '10:40', '26:15', '36:25', '26:50', '15:45',\n",
       "       '19:40', '22:25', '19:35', '25:00', '26:45', '38:00', '4:15',\n",
       "       '25:10', '18:15', '6:50', '23:55', '17:55', '23:25', '17:10',\n",
       "       '24:20', '28:30', '27:10', '19:20', '15:35', '9:25', '21:30',\n",
       "       '34:25', '18:35', '29:40', '26:05', '29:05', '27:25', '16:30',\n",
       "       '11:10', '28:55', '29:10', '34:00', '30:40', '30:45', '32:55',\n",
       "       '10:05', '35:20', '32:05', '31:40', '19:50', '33:45', '30:10',\n",
       "       '13:40', '19:30', '31:30', '34:30', '27:50', '38:35', '42:05',\n",
       "       '4:10', '39:05', '3:50', '5', '32:30', '31:55', '33:20', '27:30',\n",
       "       '18:55', '9:55', '41:20', '20:05', '31:50', '42:45', '3:25',\n",
       "       '37:10', '29:30', '32:20', '20:50', '40:20', '13:35', '47:40'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 738,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Duration'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c65f3a0-6aac-475e-a7ca-847bbceb2ad0",
   "metadata": {},
   "source": [
    "The previous output doesn't really help us to immediately spot the 5m entry.  \n",
    "We must find another way to check those records that are in a different format than the most common one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "id": "31e1137d-2cf5-4b51-a54e-21c5a7e7d10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date_of_Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep_Time</th>\n",
       "      <th>Arrival_Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Additional_Info</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>18/06/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>BLR â†’ DEL</td>\n",
       "      <td>21:15</td>\n",
       "      <td>00:15 19 Jun</td>\n",
       "      <td>3h</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>3943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>21/03/2019</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL â†’ BLR â†’ COK</td>\n",
       "      <td>05:05</td>\n",
       "      <td>10:05</td>\n",
       "      <td>5h</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>6893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>3/06/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>BLR â†’ DEL</td>\n",
       "      <td>19:50</td>\n",
       "      <td>22:50</td>\n",
       "      <td>3h</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>In-flight meal not included</td>\n",
       "      <td>6478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Air India</td>\n",
       "      <td>21/03/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR â†’ MAA â†’ DEL</td>\n",
       "      <td>11:50</td>\n",
       "      <td>19:50</td>\n",
       "      <td>8h</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>5932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Multiple carriers</td>\n",
       "      <td>9/04/2019</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL â†’ BOM â†’ COK</td>\n",
       "      <td>17:30</td>\n",
       "      <td>01:30 10 Apr</td>\n",
       "      <td>8h</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>13017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10496</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>1/05/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>BLR â†’ DEL</td>\n",
       "      <td>07:10</td>\n",
       "      <td>10:10</td>\n",
       "      <td>3h</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>In-flight meal not included</td>\n",
       "      <td>4030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10512</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>12/06/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>BLR â†’ DEL</td>\n",
       "      <td>07:10</td>\n",
       "      <td>10:10</td>\n",
       "      <td>3h</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>In-flight meal not included</td>\n",
       "      <td>5769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10529</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>12/04/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>BLR â†’ DEL</td>\n",
       "      <td>07:10</td>\n",
       "      <td>10:10</td>\n",
       "      <td>3h</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>7229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10530</th>\n",
       "      <td>Air India</td>\n",
       "      <td>03/03/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR â†’ HYD â†’ DEL</td>\n",
       "      <td>08:15</td>\n",
       "      <td>12:15</td>\n",
       "      <td>4h</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>6273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10680</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>27/04/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>BLR â†’ DEL</td>\n",
       "      <td>08:20</td>\n",
       "      <td>11:20</td>\n",
       "      <td>3h</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>7229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>516 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Airline Date_of_Journey    Source Destination  \\\n",
       "53                IndiGo      18/06/2019  Banglore       Delhi   \n",
       "74                IndiGo      21/03/2019     Delhi      Cochin   \n",
       "97           Jet Airways       3/06/2019  Banglore       Delhi   \n",
       "130            Air India      21/03/2019  Banglore   New Delhi   \n",
       "140    Multiple carriers       9/04/2019     Delhi      Cochin   \n",
       "...                  ...             ...       ...         ...   \n",
       "10496        Jet Airways       1/05/2019  Banglore       Delhi   \n",
       "10512        Jet Airways      12/06/2019  Banglore       Delhi   \n",
       "10529        Jet Airways      12/04/2019  Banglore       Delhi   \n",
       "10530          Air India      03/03/2019  Banglore   New Delhi   \n",
       "10680        Jet Airways      27/04/2019  Banglore       Delhi   \n",
       "\n",
       "                 Route Dep_Time  Arrival_Time Duration Total_Stops  \\\n",
       "53           BLR â†’ DEL    21:15  00:15 19 Jun       3h    non-stop   \n",
       "74     DEL â†’ BLR â†’ COK    05:05         10:05       5h      1 stop   \n",
       "97           BLR â†’ DEL    19:50         22:50       3h    non-stop   \n",
       "130    BLR â†’ MAA â†’ DEL    11:50         19:50       8h      1 stop   \n",
       "140    DEL â†’ BOM â†’ COK    17:30  01:30 10 Apr       8h      1 stop   \n",
       "...                ...      ...           ...      ...         ...   \n",
       "10496        BLR â†’ DEL    07:10         10:10       3h    non-stop   \n",
       "10512        BLR â†’ DEL    07:10         10:10       3h    non-stop   \n",
       "10529        BLR â†’ DEL    07:10         10:10       3h    non-stop   \n",
       "10530  BLR â†’ HYD â†’ DEL    08:15         12:15       4h      1 stop   \n",
       "10680        BLR â†’ DEL    08:20         11:20       3h    non-stop   \n",
       "\n",
       "                   Additional_Info  Price  \n",
       "53                         No info   3943  \n",
       "74                         No info   6893  \n",
       "97     In-flight meal not included   6478  \n",
       "130                        No info   5932  \n",
       "140                        No info  13017  \n",
       "...                            ...    ...  \n",
       "10496  In-flight meal not included   4030  \n",
       "10512  In-flight meal not included   5769  \n",
       "10529                      No info   7229  \n",
       "10530                      No info   6273  \n",
       "10680                      No info   7229  \n",
       "\n",
       "[516 rows x 11 columns]"
      ]
     },
     "execution_count": 741,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for Duration with entries/strings that present a lenght smaller than the common format in the original dataset\n",
    "df[df['Duration'].str.len()<3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3187a254-4270-4236-9e04-6db494e13373",
   "metadata": {},
   "source": [
    "The previous approach doesn't help either since also entries with only the hour (19h) has the same lenght as the ones with only minuts (5m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "id": "e49131ba-cf60-4dac-8ae2-c08113f4cb97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date_of_Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep_Time</th>\n",
       "      <th>Arrival_Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Additional_Info</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6474</th>\n",
       "      <td>Air India</td>\n",
       "      <td>6/03/2019</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>BOM â†’ GOI â†’ PNQ â†’ HYD</td>\n",
       "      <td>16:50</td>\n",
       "      <td>16:55</td>\n",
       "      <td>5m</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>17327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Airline Date_of_Journey  Source Destination                  Route  \\\n",
       "6474  Air India       6/03/2019  Mumbai   Hyderabad  BOM â†’ GOI â†’ PNQ â†’ HYD   \n",
       "\n",
       "     Dep_Time Arrival_Time Duration Total_Stops Additional_Info  Price  \n",
       "6474    16:50        16:55       5m     2 stops         No info  17327  "
      ]
     },
     "execution_count": 744,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking which rows contain only minutes and not hours in the original dataset\n",
    "df[(df['Duration'].str.contains('m')) & (~df['Duration'].str.contains('h'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "id": "189a88ad-d187-4af9-936e-2c9cab9d487c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 11)"
      ]
     },
     "execution_count": 746,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['Duration'].str.contains('m')) & (~df['Duration'].str.contains('h'))].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3f5b0a-07de-4099-a687-11dc198cf260",
   "metadata": {},
   "source": [
    "This check found only one entry with this kind of Duration. It's reasonable to assume this was a standalone mistake and directly dropping will have no further consequences as any imputation method or analysis would be suprefluos: an imputation method for just one record could be potentially misleading!\n",
    "\n",
    "#### NOTE: Accidents Happen\n",
    "This incorrect record was found in a previous analysis by accident: in fact, while trying to change the data type of Duration, Python raised an error.\n",
    "This is a clear sign that it's impossible to check every record perfectly and sometimes luck is the best help we can hope for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "id": "1f560ade-dd60-40bc-adc0-47cb0f6be369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date of Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep Time</th>\n",
       "      <th>Arr Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total Stops</th>\n",
       "      <th>Additional Info</th>\n",
       "      <th>Price</th>\n",
       "      <th>Arrival_Time_Hour</th>\n",
       "      <th>Dep_Time_Dummy</th>\n",
       "      <th>Dep_Time_Hour</th>\n",
       "      <th>Arrival_Time_Dummy</th>\n",
       "      <th>Duration_todrop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6474</th>\n",
       "      <td>Air India</td>\n",
       "      <td>2019-03-06</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>BOM â†’ GOI â†’ PNQ â†’ HYD</td>\n",
       "      <td>16:50</td>\n",
       "      <td>16:55</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>No info</td>\n",
       "      <td>17327</td>\n",
       "      <td>16:55:00</td>\n",
       "      <td>1900-01-01 16:50:00</td>\n",
       "      <td>16:50:00</td>\n",
       "      <td>1900-01-01 16:55:00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Airline Date of Journey  Source Destination                  Route  \\\n",
       "6474  Air India      2019-03-06  Mumbai   Hyderabad  BOM â†’ GOI â†’ PNQ â†’ HYD   \n",
       "\n",
       "     Dep Time Arr Time Duration  Total Stops Additional Info  Price  \\\n",
       "6474    16:50    16:55        5            2         No info  17327   \n",
       "\n",
       "     Arrival_Time_Hour      Dep_Time_Dummy Dep_Time_Hour  Arrival_Time_Dummy  \\\n",
       "6474          16:55:00 1900-01-01 16:50:00      16:50:00 1900-01-01 16:55:00   \n",
       "\n",
       "      Duration_todrop  \n",
       "6474              5.0  "
      ]
     },
     "execution_count": 749,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the corresponding df row in df_copy\n",
    "df_copy.loc[[6474]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "id": "9e8ebb3c-2152-444d-9e55-e8dbd9a1f7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_copy.drop(6474)\n",
    "\n",
    "#or\n",
    "\n",
    "#df_copy.drop(6474, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae17c020-771c-41eb-aee4-47679bc6736e",
   "metadata": {},
   "source": [
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8333e8be-b7ae-47d4-a9cf-b342992ec1e3",
   "metadata": {},
   "source": [
    "Though we already found the minimum as a bad record, we can finally compare similar Durations to see if there's any duration that is too short compared to other similar flights.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "id": "e72e298a-48a1-4ae0-a5e1-8a924f143f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.15"
      ]
     },
     "execution_count": 755,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Duration_todrop'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "id": "6b55dd68-187f-427c-bdd7-061738133a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1:20\n",
       "Name: Duration, dtype: object"
      ]
     },
     "execution_count": 757,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing the minimum with the mode of the duration for the same flight\n",
    "df_copy[(df_copy['Source']=='Mumbai') & (df_copy['Destination']=='Hyderabad') & (df_copy['Airline']=='Air India')]['Duration'].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b61a4b-6f84-44bd-83fc-de28707950a1",
   "metadata": {},
   "source": [
    "#### Insights\n",
    "Considering that the mode duration for flights from Mumbai to Hyderabad is 1 hour and 20 minutes, a minimum duration of 1 hour and 15 minutes appears plausible.\n",
    "\n",
    "On the higher end of the spectrum, a maximum flight duration of 47.4 hours seems unusually long. While this could represent a rare but real occurrence (e.g., major delays or reroutes), further exploratory data analysis (EDA) will help determine whether itâ€™s appropriate to treat this as an outlier and potentially exclude it from the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b40111-aa57-4acc-919a-76ae72d8ccda",
   "metadata": {},
   "source": [
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·\n",
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d19219-2197-4721-abfc-9a70c3fe6a20",
   "metadata": {},
   "source": [
    "#### 6.4 Consistency check between Route and Total Stops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "id": "014db1de-451a-4877-9640-0d268fe805d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 16)"
      ]
     },
     "execution_count": 762,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing Total Stops with number of airport (=stops) in Route\n",
    "df_copy[df_copy['Total Stops']!=(df_copy['Route'].str.count('â†’')-1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "id": "6ed13182-f70e-4e38-9845-9d498af127f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date of Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep Time</th>\n",
       "      <th>Arr Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total Stops</th>\n",
       "      <th>Additional Info</th>\n",
       "      <th>Price</th>\n",
       "      <th>Arrival_Time_Hour</th>\n",
       "      <th>Dep_Time_Dummy</th>\n",
       "      <th>Dep_Time_Hour</th>\n",
       "      <th>Arrival_Time_Dummy</th>\n",
       "      <th>Duration_todrop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>2019-03-24</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR â†’ DEL</td>\n",
       "      <td>22:20</td>\n",
       "      <td>01:10 22 Mar</td>\n",
       "      <td>2:50</td>\n",
       "      <td>0</td>\n",
       "      <td>No info</td>\n",
       "      <td>3897</td>\n",
       "      <td>01:10:00</td>\n",
       "      <td>1900-01-01 22:20:00</td>\n",
       "      <td>22:20:00</td>\n",
       "      <td>1900-01-01 01:10:00</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air India</td>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU â†’ IXR â†’ BBI â†’ BLR</td>\n",
       "      <td>05:50</td>\n",
       "      <td>13:15</td>\n",
       "      <td>7:25</td>\n",
       "      <td>2</td>\n",
       "      <td>No info</td>\n",
       "      <td>7662</td>\n",
       "      <td>13:15:00</td>\n",
       "      <td>1900-01-01 05:50:00</td>\n",
       "      <td>05:50:00</td>\n",
       "      <td>1900-01-01 13:15:00</td>\n",
       "      <td>7.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>2019-06-09</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL â†’ LKO â†’ BOM â†’ COK</td>\n",
       "      <td>09:25</td>\n",
       "      <td>04:25 10 Jun</td>\n",
       "      <td>19:00</td>\n",
       "      <td>2</td>\n",
       "      <td>No info</td>\n",
       "      <td>13882</td>\n",
       "      <td>04:25:00</td>\n",
       "      <td>1900-01-01 09:25:00</td>\n",
       "      <td>09:25:00</td>\n",
       "      <td>1900-01-01 04:25:00</td>\n",
       "      <td>19.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Airline Date of Journey    Source Destination                  Route  \\\n",
       "0       IndiGo      2019-03-24  Banglore   New Delhi              BLR â†’ DEL   \n",
       "1    Air India      2019-05-01   Kolkata    Banglore  CCU â†’ IXR â†’ BBI â†’ BLR   \n",
       "2  Jet Airways      2019-06-09     Delhi      Cochin  DEL â†’ LKO â†’ BOM â†’ COK   \n",
       "\n",
       "  Dep Time      Arr Time Duration  Total Stops Additional Info  Price  \\\n",
       "0    22:20  01:10 22 Mar     2:50            0         No info   3897   \n",
       "1    05:50         13:15     7:25            2         No info   7662   \n",
       "2    09:25  04:25 10 Jun    19:00            2         No info  13882   \n",
       "\n",
       "  Arrival_Time_Hour      Dep_Time_Dummy Dep_Time_Hour  Arrival_Time_Dummy  \\\n",
       "0          01:10:00 1900-01-01 22:20:00      22:20:00 1900-01-01 01:10:00   \n",
       "1          13:15:00 1900-01-01 05:50:00      05:50:00 1900-01-01 13:15:00   \n",
       "2          04:25:00 1900-01-01 09:25:00      09:25:00 1900-01-01 04:25:00   \n",
       "\n",
       "   Duration_todrop  \n",
       "0             2.50  \n",
       "1             7.25  \n",
       "2            19.00  "
      ]
     },
     "execution_count": 766,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dfd355-6d3a-4038-a444-10a10925aa20",
   "metadata": {},
   "source": [
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·\n",
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·\n",
    "ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·ðŸ”·"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6fd8af-880a-401f-a8a6-54da7506f6aa",
   "metadata": {},
   "source": [
    "### Exporting Dataset so it keeps the data types implemented in this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb308cb3-a69d-4aee-b53b-7e4841475559",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.to_parquet('cleaned dataset.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7d8085-f3b7-40d8-814d-23b90af0f24b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c5a52fc-f261-4fee-931a-48ddc02d1a3f",
   "metadata": {},
   "source": [
    "### Attempt of automation of the data cleaning process (work in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "id": "91671224-7adb-41ed-b16a-dd0281595718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(df, verbose = True):\n",
    "    print('1.1 RETRIEVING GENERAL INFO ABOUT THE DATASET\\n')\n",
    "    df.info()\n",
    "    print('\\n-------------------------------------')\n",
    "    print(f\"\\n1.2 TOTAL NUMBER OF ROWS AND COLUMN: {df.shape}\")\n",
    "    print('\\n-------------------------------------')\n",
    "    print('\\n1.3 ASSESSING UNIQUE VALUES FOR EACH FEATURE')\n",
    "    max_unique = int(input('What is the acceptable max number of unique values? '))\n",
    "    for col in df:\n",
    "        unique_count = df[col].nunique()\n",
    "        print()\n",
    "        print(f\"Unique records count for '{col}': {unique_count}\")\n",
    "        \n",
    "        if df[col].nunique() < max_unique:\n",
    "            unique_value = df[col].unique()\n",
    "            print(f\"The unique values for {col} are \\n{unique_value}\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"The number of unique records for {col} is too high to be easily interpretable\")\n",
    "            pass\n",
    "    \n",
    "    print ('\\n-------------------------------------')\n",
    "    print('\\n CREATION OF A COPY OF THE DATASET TO WORK WITH')\n",
    "    df_copy = df.copy()\n",
    "    print ('\\n-------------------------------------')\n",
    "    \n",
    "    print('\\n2. IDENTIFYING AND HANDLING DUPLICATE ROWS\\n')\n",
    "    duplicate = df_copy.duplicated()\n",
    "    print(f\" Number of duplicate rows excluding the first one: {duplicate.sum()}\")\n",
    "    \n",
    "    print('\\nGiven the nature of this dataset - identical flights are not possible -'\n",
    "          \"it's convenient to drop duplicates\") \n",
    "    df_copy = df_copy.drop_duplicates(keep = 'first')\n",
    "    print(f\"\\nChecking the number of duplicates after elimination: {df_copy.duplicated().sum()}\")\n",
    "    print ('\\n-------------------------------------')\n",
    "\n",
    "    print('\\n3. IDENTIFYING AND HANDLING MISSING RECORDS (preliminary check)')\n",
    "    col_list = []\n",
    "    for col in df_copy:\n",
    "        if df_copy[col].isnull().any():\n",
    "            col_list.append(col)\n",
    "            missing_value = df_copy[col].isnull().sum()\n",
    "            print(f\"\\n'{col}' has : {missing_value}\")\n",
    "        else:\n",
    "            pass\n",
    "    nan_rows = df_copy[df_copy['Route'].isnull() | df_copy['Total_Stops'].isnull()]\n",
    "    print('\\nAddressing the rows with missing values:\\n') \n",
    "    print(nan_rows.to_string(index=False))\n",
    "\n",
    "    print(\"\\nBoth missing values are in the same row, dropping only row won't affect the analysis!\")\n",
    "\n",
    "    print ('\\n-------------------------------------')\n",
    "\n",
    "    print('\\n4. FIXING FORMAT AND STRUCTURAL ISSUES')\n",
    "    print('\\n4.1 Extracting time from Arrival_Time')\n",
    "    arrival_time_hour = df_copy['Arrival_Time_Hour'] = df_copy['Arrival_Time'].str.split(' ').str[0]\n",
    "    display(arrival_time_hour)\n",
    "    print('\\n4.1 Extracting time from Duration')\n",
    "    df_copy['Duration']=df['Duration'].str.replace('h ',':')\n",
    "    df_copy['Duration'] = df_copy['Duration'].str.replace('h', ':00')\n",
    "    duration = df_copy['Duration'] = df_copy['Duration'].str.replace('m','')\n",
    "    display(duration)\n",
    "    print('\\n4.1 Extracting the number of stops from Total_Stops')\n",
    "    df_copy['Total_Stops'] = df_copy['Total_Stops'].str.replace('non-stop','0')\n",
    "    df_copy['Total_Stops'] = df_copy['Total_Stops'].str.split(' ').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "id": "fcaaefeb-ad34-4aa5-9f11-67ae2a2b6567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 RETRIEVING GENERAL INFO ABOUT THE DATASET\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10683 entries, 0 to 10682\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Airline          10683 non-null  object\n",
      " 1   Date_of_Journey  10683 non-null  object\n",
      " 2   Source           10683 non-null  object\n",
      " 3   Destination      10683 non-null  object\n",
      " 4   Route            10682 non-null  object\n",
      " 5   Dep_Time         10683 non-null  object\n",
      " 6   Arrival_Time     10683 non-null  object\n",
      " 7   Duration         10683 non-null  object\n",
      " 8   Total_Stops      10682 non-null  object\n",
      " 9   Additional_Info  10683 non-null  object\n",
      " 10  Price            10683 non-null  int64 \n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 918.2+ KB\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "1.2 TOTAL NUMBER OF ROWS AND COLUMN: (10683, 11)\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "1.3 ASSESSING UNIQUE VALUES FOR EACH FEATURE\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What is the acceptable max number of unique values?  10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique records count for 'Airline': 12\n",
      "The number of unique records for Airline is too high to be easily interpretable\n",
      "\n",
      "Unique records count for 'Date_of_Journey': 44\n",
      "The number of unique records for Date_of_Journey is too high to be easily interpretable\n",
      "\n",
      "Unique records count for 'Source': 5\n",
      "The unique values for Source are \n",
      "['Banglore' 'Kolkata' 'Delhi' 'Chennai' 'Mumbai']\n",
      "\n",
      "Unique records count for 'Destination': 6\n",
      "The unique values for Destination are \n",
      "['New Delhi' 'Banglore' 'Cochin' 'Kolkata' 'Delhi' 'Hyderabad']\n",
      "\n",
      "Unique records count for 'Route': 128\n",
      "The number of unique records for Route is too high to be easily interpretable\n",
      "\n",
      "Unique records count for 'Dep_Time': 222\n",
      "The number of unique records for Dep_Time is too high to be easily interpretable\n",
      "\n",
      "Unique records count for 'Arrival_Time': 1343\n",
      "The number of unique records for Arrival_Time is too high to be easily interpretable\n",
      "\n",
      "Unique records count for 'Duration': 368\n",
      "The number of unique records for Duration is too high to be easily interpretable\n",
      "\n",
      "Unique records count for 'Total_Stops': 5\n",
      "The unique values for Total_Stops are \n",
      "['non-stop' '2 stops' '1 stop' '3 stops' nan '4 stops']\n",
      "\n",
      "Unique records count for 'Additional_Info': 10\n",
      "The number of unique records for Additional_Info is too high to be easily interpretable\n",
      "\n",
      "Unique records count for 'Price': 1870\n",
      "The number of unique records for Price is too high to be easily interpretable\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      " CREATION OF A COPY OF THE DATASET TO WORK WITH\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "2. IDENTIFYING AND HANDLING DUPLICATE ROWS\n",
      "\n",
      " Number of duplicate rows excluding the first one: 220\n",
      "\n",
      "Given the nature of this dataset - identical flights are not possible -it's convenient to drop duplicates\n",
      "\n",
      "Checking the number of duplicates after elimination: 0\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "3. IDENTIFYING AND HANDLING MISSING RECORDS (preliminary check)\n",
      "\n",
      "'Route' has : 1\n",
      "\n",
      "'Total_Stops' has : 1\n",
      "\n",
      "Addressing the rows with missing values:\n",
      "\n",
      "  Airline Date_of_Journey Source Destination Route Dep_Time Arrival_Time Duration Total_Stops Additional_Info  Price\n",
      "Air India       6/05/2019  Delhi      Cochin   NaN    09:45 09:25 07 May  23h 40m         NaN         No info   7480\n",
      "\n",
      "Both missing values are in the same row, dropping only row won't affect the analysis!\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "4. FIXING FORMAT AND STRUCTURAL ISSUES\n",
      "\n",
      "4.1 Extracting time from Arrival_Time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        01:10\n",
       "1        13:15\n",
       "2        04:25\n",
       "3        23:30\n",
       "4        21:35\n",
       "         ...  \n",
       "10678    22:25\n",
       "10679    23:20\n",
       "10680    11:20\n",
       "10681    14:10\n",
       "10682    19:15\n",
       "Name: Arrival_Time, Length: 10463, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4.1 Extracting time from Duration\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         2:50\n",
       "1         7:25\n",
       "2        19:00\n",
       "3         5:25\n",
       "4         4:45\n",
       "         ...  \n",
       "10678     2:30\n",
       "10679     2:35\n",
       "10680     3:00\n",
       "10681     2:40\n",
       "10682     8:20\n",
       "Name: Duration, Length: 10463, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4.1 Extracting the number of stops from Total_Stops\n"
     ]
    }
   ],
   "source": [
    "data_cleaning(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1c983d-3a7a-4d9d-92d4-f2895db47fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
